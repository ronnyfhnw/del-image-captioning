{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "23FSvPla9GDC"
      },
      "outputs": [],
      "source": [
        "# import python file from parent folder\n",
        "from img_cap_lib import *\n",
        "# imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torchtext\n",
        "from torchtext.vocab import vocab, GloVe, Vectors\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import os\n",
        "from PIL import Image\n",
        "import string\n",
        "from collections import OrderedDict, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import os\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImcPlOrB9GDG"
      },
      "source": [
        "# Daten herunterladen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or3FdVAM9GDH",
        "outputId": "541d19a1-bce5-4501-cc95-3b818fcf4ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data already exi sts at flickr8k\n"
          ]
        }
      ],
      "source": [
        "data_download(\"flickr8k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZovGtMKV9GDK"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdgY3n_J9GDK",
        "outputId": "bd9c3ed6-7d1a-46da-8481-5cc3c4306580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape captions: (40460, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ronnyschneeberger/Documents/FHNW/HS22/del-image-captioning/img_cap_lib.py:107: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.captions.caption = self.captions.caption.apply(lambda x: x.strip(\".\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape captions after filtering: (39749, 3)\n",
            "Removed Captions:  711 , in Percent:  1.76\n",
            "transformed_images folder already exists. No preprocessing necessary.\n"
          ]
        }
      ],
      "source": [
        "# caption preprocessing\n",
        "embedding_dim = 300\n",
        "min_frequency = 1\n",
        "\n",
        "captions = pd.read_csv(\"flickr8k/captions.txt\")\n",
        "caption_preprocessor = CaptionPreprocessor(captions=captions, embedding_dim=embedding_dim, min_frequency=min_frequency)\n",
        "caption_preprocessor.preprocess()\n",
        "\n",
        "# image preprocessing\n",
        "img_preprocessor = ImagePreprocessor(normalize=True, image_folder_path=\"flickr8k\")\n",
        "img_preprocessor.preprocess_images()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nl3NT_K9GDL"
      },
      "source": [
        "# Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aQ07VI9R9GDM"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "training_data, test_data = train_test_split(caption_preprocessor.captions, test_size=0.15, random_state=42)\n",
        "\n",
        "embedding = Embedding(embedding_matrix=caption_preprocessor.embedding, vocabulary=caption_preprocessor.vocabulary)\n",
        "\n",
        "# create dataset\n",
        "train_dataset = FlickrDataset(captions=training_data, embedding=embedding)\n",
        "test_dataset = FlickrDataset(captions=test_data, embedding=embedding)\n",
        "\n",
        "# create dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-254t2-t9GDN"
      },
      "source": [
        "# Modell erstellen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "9fff5a57e9f34b59bb4e69be3cc04e9e",
            "0ea2d7f30ded4b0aa661cd1b63da644a",
            "6f6b7d55bf3a486f89aa2fc407b3b3e2",
            "dd109543e2c54b53b82e38c9b5e9da44",
            "cb539266fc76422d89dea25f7e1ed012",
            "5389d28534dd43a3af22a13e426effae",
            "3b9ded511f9c46cd96e212cb0365269b",
            "70ad6c60af024efc86f26227c10303ab",
            "7d6bc20bd45845ea93ba03b01737623f",
            "8ebf7b02ecb74a319762bbb212a1645a",
            "38247c71882a491fad78052adb334296"
          ]
        },
        "id": "s8MBnXU09GDN",
        "outputId": "0d382437-24cc-4c98-a486-2de5c1e51534"
      },
      "outputs": [],
      "source": [
        "if \"standart.pt\" in os.listdir():\n",
        "    model_stats = torch.load(\"standart.pt\")\n",
        "    model = load_captioning_model(model_stats)\n",
        "else:\n",
        "    encoder = EncoderCNN(net=torchvision.models.resnext50_32x4d, pretrained_weights=torchvision.models.ResNeXt50_32X4D_Weights.IMAGENET1K_V2, output_size=300)\n",
        "    decoder = DecoderRNN(input_size=300, hidden_size=caption_preprocessor.embedding_dim, num_layers=1, dropout=0.0, len_vocab=embedding.embedding_matrix.shape[0], len_subtract=0)\n",
        "    model = ImageCaptioning(encoder=encoder, decoder=decoder, embedding=embedding, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/1 | Batch: 1/527 | Loss: 1.29318368434906\n",
            "Epoch: 1/1 | Batch: 2/527 | Loss: 1.9721699953079224\n",
            "Epoch: 1/1 | Batch: 3/527 | Loss: 2.5652785301208496\n",
            "Epoch: 1/1 | Batch: 4/527 | Loss: 2.14449143409729\n",
            "Epoch: 1/1 | Batch: 5/527 | Loss: 3.046929359436035\n",
            "Epoch: 1/1 | Batch: 6/527 | Loss: 2.757331371307373\n",
            "Epoch: 1/1 | Batch: 7/527 | Loss: 2.5614356994628906\n",
            "Epoch: 1/1 | Batch: 8/527 | Loss: 2.1697428226470947\n",
            "Epoch: 1/1 | Batch: 9/527 | Loss: 2.110513687133789\n",
            "Epoch: 1/1 | Batch: 10/527 | Loss: 2.930253505706787\n",
            "Epoch: 1/1 | Batch: 11/527 | Loss: 2.250471591949463\n",
            "Epoch: 1/1 | Batch: 12/527 | Loss: 2.630889654159546\n",
            "Epoch: 1/1 | Batch: 13/527 | Loss: 2.4383749961853027\n",
            "Epoch: 1/1 | Batch: 14/527 | Loss: 2.949169874191284\n",
            "Epoch: 1/1 | Batch: 15/527 | Loss: 2.97184157371521\n",
            "Epoch: 1/1 | Batch: 16/527 | Loss: 2.0929834842681885\n",
            "Epoch: 1/1 | Batch: 17/527 | Loss: 2.8149142265319824\n",
            "Epoch: 1/1 | Batch: 18/527 | Loss: 2.2896153926849365\n",
            "Epoch: 1/1 | Batch: 19/527 | Loss: 2.4711496829986572\n",
            "Epoch: 1/1 | Batch: 20/527 | Loss: 2.2483251094818115\n",
            "Epoch: 1/1 | Batch: 21/527 | Loss: 2.251147747039795\n",
            "Epoch: 1/1 | Batch: 22/527 | Loss: 2.419018268585205\n",
            "Epoch: 1/1 | Batch: 23/527 | Loss: 2.5988502502441406\n",
            "Epoch: 1/1 | Batch: 24/527 | Loss: 2.589916706085205\n",
            "Epoch: 1/1 | Batch: 25/527 | Loss: 2.3016436100006104\n",
            "Epoch: 1/1 | Batch: 26/527 | Loss: 2.6726245880126953\n",
            "Epoch: 1/1 | Batch: 27/527 | Loss: 2.2331411838531494\n",
            "Epoch: 1/1 | Batch: 28/527 | Loss: 2.267545461654663\n",
            "Epoch: 1/1 | Batch: 29/527 | Loss: 3.296553611755371\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m temp_model_stats \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mmodels/temp_model.pt\u001b[39m\u001b[39m\"\u001b[39m, map_location\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(device))\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m load_captioning_model(temp_model_stats)\n\u001b[0;32m----> 4\u001b[0m model\u001b[39m.\u001b[39mtrain_model(loader\u001b[39m=\u001b[39mtrain_loader, optimizer\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m), criterion\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss(), epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, print_every\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m~/Documents/FHNW/HS22/del-image-captioning/img_cap_lib.py:609\u001b[0m, in \u001b[0;36mImageCaptioning.train_model\u001b[0;34m(self, loader, optimizer, criterion, epochs, print_every)\u001b[0m\n\u001b[1;32m    606\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    608\u001b[0m \u001b[39m# backpropagate loss\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    611\u001b[0m \u001b[39m# update weights\u001b[39;00m\n\u001b[1;32m    612\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
            "File \u001b[0;32m~/Documents/FHNW/HS22/del-image-captioning/venv/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[0;32m~/Documents/FHNW/HS22/del-image-captioning/venv/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "temp_model_stats = torch.load(\"models/temp_model.pt\", map_location=torch.device(device))\n",
        "model = load_captioning_model(temp_model_stats)\n",
        "\n",
        "model.train_model(loader=train_loader, optimizer=torch.optim.Adam(model.parameters(), lr=0.01), criterion=torch.nn.CrossEntropyLoss(), epochs=1, print_every=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02luogN-9GDO",
        "outputId": "56de3971-40ae-409f-de2a-8b6b58c533f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/250 | Batch: 1/527 | Loss: 9.025182723999023\n",
            "Epoch: 1/250 | Average Epoch Loss: 5.990393426884284\n",
            "Epoch: 2/250 | Batch: 1/527 | Loss: 5.4601640701293945\n",
            "Epoch: 2/250 | Average Epoch Loss: 5.229636007739652\n",
            "Epoch: 3/250 | Batch: 1/527 | Loss: 5.013434886932373\n",
            "Epoch: 3/250 | Average Epoch Loss: 4.777546999350444\n",
            "Epoch: 4/250 | Batch: 1/527 | Loss: 4.598186492919922\n",
            "Epoch: 4/250 | Average Epoch Loss: 4.37486219225165\n",
            "Epoch: 5/250 | Batch: 1/527 | Loss: 4.058480739593506\n",
            "Epoch: 5/250 | Average Epoch Loss: 4.002896713350936\n",
            "Epoch: 6/250 | Batch: 1/527 | Loss: 3.611685276031494\n",
            "Epoch: 6/250 | Average Epoch Loss: 3.6396884777966667\n",
            "Epoch: 7/250 | Batch: 1/527 | Loss: 3.206207036972046\n",
            "Epoch: 7/250 | Average Epoch Loss: 3.2965542238622736\n",
            "Epoch: 8/250 | Batch: 1/527 | Loss: 3.3456461429595947\n",
            "Epoch: 8/250 | Average Epoch Loss: 2.9615128452004247\n",
            "Epoch: 9/250 | Batch: 1/527 | Loss: 2.731268882751465\n",
            "Epoch: 9/250 | Average Epoch Loss: 2.6515791284970134\n",
            "Epoch: 10/250 | Batch: 1/527 | Loss: 2.807574987411499\n",
            "Epoch: 10/250 | Average Epoch Loss: 2.37247173134697\n",
            "Epoch: 11/250 | Batch: 1/527 | Loss: 2.2593891620635986\n",
            "Epoch: 11/250 | Average Epoch Loss: 2.1529394833819917\n",
            "Epoch: 12/250 | Batch: 1/527 | Loss: 2.0528156757354736\n",
            "Epoch: 12/250 | Average Epoch Loss: 1.9676018414958831\n",
            "Epoch: 13/250 | Batch: 1/527 | Loss: 1.8711796998977661\n",
            "Epoch: 13/250 | Average Epoch Loss: 1.8265280963347579\n",
            "Epoch: 14/250 | Batch: 1/527 | Loss: 1.6402837038040161\n",
            "Epoch: 14/250 | Average Epoch Loss: 1.7270203672731173\n",
            "Epoch: 15/250 | Batch: 1/527 | Loss: 1.2780165672302246\n",
            "Epoch: 15/250 | Average Epoch Loss: 1.6501985007942968\n",
            "Epoch: 16/250 | Batch: 1/527 | Loss: 1.618246078491211\n",
            "Epoch: 16/250 | Average Epoch Loss: 1.608377520002043\n",
            "Epoch: 17/250 | Batch: 1/527 | Loss: 2.226459503173828\n",
            "Epoch: 17/250 | Average Epoch Loss: 1.5554044857423264\n",
            "Epoch: 18/250 | Batch: 1/527 | Loss: 1.8289474248886108\n",
            "Epoch: 18/250 | Average Epoch Loss: 1.5042480110443521\n",
            "Epoch: 19/250 | Batch: 1/527 | Loss: 1.1702799797058105\n",
            "Epoch: 19/250 | Average Epoch Loss: 1.4787447481951632\n",
            "Epoch: 20/250 | Batch: 1/527 | Loss: 1.4987200498580933\n",
            "Epoch: 20/250 | Average Epoch Loss: 1.419989161179233\n",
            "Epoch: 21/250 | Batch: 1/527 | Loss: 1.1249802112579346\n",
            "Epoch: 21/250 | Average Epoch Loss: 1.4145894990474042\n",
            "Epoch: 22/250 | Batch: 1/527 | Loss: 1.0242116451263428\n",
            "Epoch: 22/250 | Average Epoch Loss: 1.3872905404110787\n",
            "Epoch: 23/250 | Batch: 1/527 | Loss: 1.3885531425476074\n",
            "Epoch: 23/250 | Average Epoch Loss: 1.3726961781223088\n",
            "Epoch: 24/250 | Batch: 1/527 | Loss: 1.3760087490081787\n",
            "Epoch: 24/250 | Average Epoch Loss: 1.3258599118670658\n",
            "Epoch: 25/250 | Batch: 1/527 | Loss: 0.9453659057617188\n",
            "Epoch: 25/250 | Average Epoch Loss: 1.316957098256931\n",
            "Epoch: 26/250 | Batch: 1/527 | Loss: 1.312562346458435\n",
            "Epoch: 26/250 | Average Epoch Loss: 1.2977579384193927\n",
            "Epoch: 27/250 | Batch: 1/527 | Loss: 1.6452217102050781\n",
            "Epoch: 27/250 | Average Epoch Loss: 1.2871826023033042\n",
            "Epoch: 28/250 | Batch: 1/527 | Loss: 0.9295338988304138\n",
            "Epoch: 28/250 | Average Epoch Loss: 1.269140785740268\n",
            "Epoch: 29/250 | Batch: 1/527 | Loss: 0.8504949808120728\n",
            "Epoch: 29/250 | Average Epoch Loss: 1.2598129167050067\n",
            "Epoch: 30/250 | Batch: 1/527 | Loss: 0.8472073078155518\n",
            "Epoch: 30/250 | Average Epoch Loss: 1.2170528021890252\n",
            "Epoch: 31/250 | Batch: 1/527 | Loss: 0.8664875626564026\n",
            "Epoch: 31/250 | Average Epoch Loss: 1.220565034270965\n",
            "Epoch: 32/250 | Batch: 1/527 | Loss: 1.26310396194458\n",
            "Epoch: 32/250 | Average Epoch Loss: 1.1974195614032999\n",
            "Epoch: 33/250 | Batch: 1/527 | Loss: 1.5268616676330566\n",
            "Epoch: 33/250 | Average Epoch Loss: 1.178325460350717\n",
            "Epoch: 34/250 | Batch: 1/527 | Loss: 0.8872094750404358\n",
            "Epoch: 34/250 | Average Epoch Loss: 1.2009608596280585\n",
            "Epoch: 35/250 | Batch: 1/527 | Loss: 1.5475220680236816\n",
            "Epoch: 35/250 | Average Epoch Loss: 1.1357064637332532\n",
            "Epoch: 36/250 | Batch: 1/527 | Loss: 0.7389669418334961\n",
            "Epoch: 36/250 | Average Epoch Loss: 1.1291017954218319\n",
            "Epoch: 37/250 | Batch: 1/527 | Loss: 2.9490721225738525\n",
            "Epoch: 37/250 | Average Epoch Loss: 1.1024875427106753\n",
            "Epoch: 38/250 | Batch: 1/527 | Loss: 1.480655550956726\n",
            "Epoch: 38/250 | Average Epoch Loss: 1.0997883593787279\n",
            "Epoch: 39/250 | Batch: 1/527 | Loss: 1.4087988138198853\n",
            "Epoch: 39/250 | Average Epoch Loss: 1.1004617053598336\n",
            "Epoch: 40/250 | Batch: 1/527 | Loss: 0.7233762741088867\n",
            "Epoch: 40/250 | Average Epoch Loss: 1.0774071131756908\n",
            "Epoch: 41/250 | Batch: 1/527 | Loss: 0.7538170218467712\n",
            "Epoch: 41/250 | Average Epoch Loss: 1.0791421747524326\n",
            "Epoch: 42/250 | Batch: 1/527 | Loss: 0.7379878759384155\n",
            "Epoch: 42/250 | Average Epoch Loss: 1.0586785395864744\n",
            "Epoch: 43/250 | Batch: 1/527 | Loss: 0.6590499877929688\n",
            "Epoch: 43/250 | Average Epoch Loss: 1.0540636805022239\n",
            "Epoch: 44/250 | Batch: 1/527 | Loss: 0.9948862195014954\n",
            "Epoch: 44/250 | Average Epoch Loss: 1.009169735763738\n",
            "Epoch: 45/250 | Batch: 1/527 | Loss: 0.619201123714447\n",
            "Epoch: 45/250 | Average Epoch Loss: 1.0126046927423134\n",
            "Epoch: 46/250 | Batch: 1/527 | Loss: 0.9760996103286743\n",
            "Epoch: 46/250 | Average Epoch Loss: 1.0127976411207804\n",
            "Epoch: 47/250 | Batch: 1/527 | Loss: 1.002593994140625\n",
            "Epoch: 47/250 | Average Epoch Loss: 1.0253687321121825\n",
            "Epoch: 48/250 | Batch: 1/527 | Loss: 0.6205812096595764\n",
            "Epoch: 48/250 | Average Epoch Loss: 1.017876564099169\n",
            "Epoch: 49/250 | Batch: 1/527 | Loss: 0.6140108704566956\n",
            "Epoch: 49/250 | Average Epoch Loss: 0.9708006184060388\n",
            "Epoch: 50/250 | Batch: 1/527 | Loss: 0.5985372066497803\n",
            "Epoch: 50/250 | Average Epoch Loss: 0.9772098415038165\n",
            "Epoch: 51/250 | Batch: 1/527 | Loss: 0.546688437461853\n",
            "Epoch: 51/250 | Average Epoch Loss: 0.9442633491087231\n",
            "Epoch: 52/250 | Batch: 1/527 | Loss: 0.9303781390190125\n",
            "Epoch: 52/250 | Average Epoch Loss: 0.9150003638167987\n",
            "Epoch: 53/250 | Batch: 1/527 | Loss: 0.9127323031425476\n",
            "Epoch: 53/250 | Average Epoch Loss: 0.9211647394599227\n",
            "Epoch: 54/250 | Batch: 1/527 | Loss: 0.5644054412841797\n",
            "Epoch: 54/250 | Average Epoch Loss: 0.8731131181545004\n",
            "Epoch: 55/250 | Batch: 1/527 | Loss: 0.8807485699653625\n",
            "Epoch: 55/250 | Average Epoch Loss: 0.8876151691351715\n",
            "Epoch: 56/250 | Batch: 1/527 | Loss: 1.5778381824493408\n",
            "Epoch: 56/250 | Average Epoch Loss: 0.881031859927657\n",
            "Epoch: 57/250 | Batch: 1/527 | Loss: 1.1697068214416504\n",
            "Epoch: 57/250 | Average Epoch Loss: 0.8570919594457073\n",
            "Epoch: 58/250 | Batch: 1/527 | Loss: 0.8956523537635803\n",
            "Epoch: 58/250 | Average Epoch Loss: 0.855655619213658\n",
            "Epoch: 59/250 | Batch: 1/527 | Loss: 0.4792618453502655\n",
            "Epoch: 59/250 | Average Epoch Loss: 0.8436568668377241\n",
            "Epoch: 60/250 | Batch: 1/527 | Loss: 0.43834221363067627\n",
            "Epoch: 60/250 | Average Epoch Loss: 0.810092729906882\n",
            "Epoch: 61/250 | Batch: 1/527 | Loss: 0.45637357234954834\n",
            "Epoch: 61/250 | Average Epoch Loss: 0.8147681141713992\n",
            "Epoch: 62/250 | Batch: 1/527 | Loss: 1.521897792816162\n",
            "Epoch: 62/250 | Average Epoch Loss: 0.8138044619017353\n",
            "Epoch: 63/250 | Batch: 1/527 | Loss: 1.5279539823532104\n",
            "Epoch: 63/250 | Average Epoch Loss: 0.7937162349414102\n",
            "Epoch: 64/250 | Batch: 1/527 | Loss: 1.1606160402297974\n",
            "Epoch: 64/250 | Average Epoch Loss: 0.7846834419235107\n",
            "Epoch: 65/250 | Batch: 1/527 | Loss: 1.1300312280654907\n",
            "Epoch: 65/250 | Average Epoch Loss: 0.7720786437137755\n",
            "Epoch: 66/250 | Batch: 1/527 | Loss: 0.40549084544181824\n",
            "Epoch: 66/250 | Average Epoch Loss: 0.7740570222517118\n",
            "Epoch: 67/250 | Batch: 1/527 | Loss: 0.8025358319282532\n",
            "Epoch: 67/250 | Average Epoch Loss: 0.7638811229302264\n",
            "Epoch: 68/250 | Batch: 1/527 | Loss: 1.4869675636291504\n",
            "Epoch: 68/250 | Average Epoch Loss: 0.7560620640441634\n",
            "Epoch: 69/250 | Batch: 1/527 | Loss: 0.3553451597690582\n",
            "Epoch: 69/250 | Average Epoch Loss: 0.7372430590682961\n",
            "Epoch: 70/250 | Batch: 1/527 | Loss: 1.1299493312835693\n",
            "Epoch: 70/250 | Average Epoch Loss: 0.7376299929121187\n",
            "Epoch: 71/250 | Batch: 1/527 | Loss: 0.7635669112205505\n",
            "Epoch: 71/250 | Average Epoch Loss: 0.7154529625708962\n",
            "Epoch: 72/250 | Batch: 1/527 | Loss: 0.3760303556919098\n",
            "Epoch: 72/250 | Average Epoch Loss: 0.7527743457503744\n",
            "Epoch: 73/250 | Batch: 1/527 | Loss: 0.6918084621429443\n",
            "Epoch: 73/250 | Average Epoch Loss: 0.7203232977376717\n",
            "Epoch: 74/250 | Batch: 1/527 | Loss: 0.7018080353736877\n",
            "Epoch: 74/250 | Average Epoch Loss: 0.707719331561275\n",
            "Epoch: 75/250 | Batch: 1/527 | Loss: 0.7085484862327576\n",
            "Epoch: 75/250 | Average Epoch Loss: 0.7168193272327337\n",
            "Epoch: 76/250 | Batch: 1/527 | Loss: 0.2959545850753784\n",
            "Epoch: 76/250 | Average Epoch Loss: 0.693796365265602\n",
            "Epoch: 77/250 | Batch: 1/527 | Loss: 0.6503599286079407\n",
            "Epoch: 77/250 | Average Epoch Loss: 0.6808772629985773\n",
            "Epoch: 78/250 | Batch: 1/527 | Loss: 1.7437893152236938\n",
            "Epoch: 78/250 | Average Epoch Loss: 0.6727786652277271\n",
            "Epoch: 79/250 | Batch: 1/527 | Loss: 0.3369022607803345\n",
            "Epoch: 79/250 | Average Epoch Loss: 0.6714399804765857\n",
            "Epoch: 80/250 | Batch: 1/527 | Loss: 0.6677278280258179\n",
            "Epoch: 80/250 | Average Epoch Loss: 0.669048881734345\n",
            "Epoch: 81/250 | Batch: 1/527 | Loss: 0.2954663932323456\n",
            "Epoch: 81/250 | Average Epoch Loss: 0.66025117135817\n",
            "Epoch: 82/250 | Batch: 1/527 | Loss: 0.6528725028038025\n",
            "Epoch: 82/250 | Average Epoch Loss: 0.6542484657644547\n",
            "Epoch: 83/250 | Batch: 1/527 | Loss: 0.6620094776153564\n",
            "Epoch: 83/250 | Average Epoch Loss: 0.6556423828995431\n",
            "Epoch: 84/250 | Batch: 1/527 | Loss: 1.0058842897415161\n",
            "Epoch: 84/250 | Average Epoch Loss: 0.6542186879568805\n",
            "Epoch: 85/250 | Batch: 1/527 | Loss: 0.2769348621368408\n",
            "Epoch: 85/250 | Average Epoch Loss: 0.6335066066068762\n",
            "Epoch: 86/250 | Batch: 1/527 | Loss: 1.0404974222183228\n",
            "Epoch: 86/250 | Average Epoch Loss: 0.6310827797402467\n",
            "Epoch: 87/250 | Batch: 1/527 | Loss: 0.28155577182769775\n",
            "Epoch: 87/250 | Average Epoch Loss: 0.6221287289538917\n",
            "Epoch: 88/250 | Batch: 1/527 | Loss: 0.6133316159248352\n",
            "Epoch: 88/250 | Average Epoch Loss: 0.6157968894523733\n",
            "Epoch: 89/250 | Batch: 1/527 | Loss: 0.6417892575263977\n",
            "Epoch: 89/250 | Average Epoch Loss: 0.6107233603550316\n",
            "Epoch: 90/250 | Batch: 1/527 | Loss: 0.2570650279521942\n",
            "Epoch: 90/250 | Average Epoch Loss: 0.6128494994011504\n",
            "Epoch: 91/250 | Batch: 1/527 | Loss: 0.9726976752281189\n",
            "Epoch: 91/250 | Average Epoch Loss: 0.620141888677056\n",
            "Epoch: 92/250 | Batch: 1/527 | Loss: 0.25301313400268555\n",
            "Epoch: 92/250 | Average Epoch Loss: 0.6038017995952429\n",
            "Epoch: 93/250 | Batch: 1/527 | Loss: 0.24349325895309448\n",
            "Epoch: 93/250 | Average Epoch Loss: 0.5742173418826804\n",
            "Epoch: 94/250 | Batch: 1/527 | Loss: 0.610724687576294\n",
            "Epoch: 94/250 | Average Epoch Loss: 0.627887862287391\n",
            "Epoch: 95/250 | Batch: 1/527 | Loss: 1.7047909498214722\n",
            "Epoch: 95/250 | Average Epoch Loss: 0.6138347791369997\n",
            "Epoch: 96/250 | Batch: 1/527 | Loss: 0.5807564854621887\n",
            "Epoch: 96/250 | Average Epoch Loss: 0.5865806486507068\n",
            "Epoch: 97/250 | Batch: 1/527 | Loss: 0.24389733374118805\n",
            "Epoch: 97/250 | Average Epoch Loss: 0.5898403167385304\n",
            "Epoch: 98/250 | Batch: 1/527 | Loss: 0.6036182641983032\n",
            "Epoch: 98/250 | Average Epoch Loss: 0.5821370084891961\n",
            "Epoch: 99/250 | Batch: 1/527 | Loss: 0.23244281113147736\n",
            "Epoch: 99/250 | Average Epoch Loss: 0.5812739803962961\n",
            "Epoch: 100/250 | Batch: 1/527 | Loss: 0.596559464931488\n",
            "Epoch: 100/250 | Average Epoch Loss: 0.5692277061814828\n",
            "Epoch: 101/250 | Batch: 1/527 | Loss: 0.20035122334957123\n",
            "Epoch: 101/250 | Average Epoch Loss: 0.5879671631603585\n",
            "Epoch: 102/250 | Batch: 1/527 | Loss: 0.5755622982978821\n",
            "Epoch: 102/250 | Average Epoch Loss: 0.5865131757969648\n",
            "Epoch: 103/250 | Batch: 1/527 | Loss: 0.5635225176811218\n",
            "Epoch: 103/250 | Average Epoch Loss: 0.5791910756131956\n",
            "Epoch: 104/250 | Batch: 1/527 | Loss: 0.20898650586605072\n",
            "Epoch: 104/250 | Average Epoch Loss: 0.5848405293597216\n",
            "Epoch: 105/250 | Batch: 1/527 | Loss: 0.5801626443862915\n",
            "Epoch: 105/250 | Average Epoch Loss: 0.541443886380268\n",
            "Epoch: 106/250 | Batch: 1/527 | Loss: 0.5886081457138062\n",
            "Epoch: 106/250 | Average Epoch Loss: 0.557823362171763\n",
            "Epoch: 107/250 | Batch: 1/527 | Loss: 0.9104942083358765\n",
            "Epoch: 107/250 | Average Epoch Loss: 0.5647724357060735\n",
            "Epoch: 108/250 | Batch: 1/527 | Loss: 0.5797649025917053\n",
            "Epoch: 108/250 | Average Epoch Loss: 0.5611017204439391\n",
            "Epoch: 109/250 | Batch: 1/527 | Loss: 0.18927353620529175\n",
            "Epoch: 109/250 | Average Epoch Loss: 0.5643993842873221\n",
            "Epoch: 110/250 | Batch: 1/527 | Loss: 0.9238565564155579\n",
            "Epoch: 110/250 | Average Epoch Loss: 0.5548484105708703\n",
            "Epoch: 111/250 | Batch: 1/527 | Loss: 0.55133455991745\n",
            "Epoch: 111/250 | Average Epoch Loss: 0.5586879369034035\n",
            "Epoch: 112/250 | Batch: 1/527 | Loss: 0.19379979372024536\n",
            "Epoch: 112/250 | Average Epoch Loss: 0.5392960600653908\n",
            "Epoch: 113/250 | Batch: 1/527 | Loss: 0.9297052621841431\n",
            "Epoch: 113/250 | Average Epoch Loss: 0.5317040881746408\n",
            "Epoch: 114/250 | Batch: 1/527 | Loss: 0.18963180482387543\n",
            "Epoch: 114/250 | Average Epoch Loss: 0.5423228834283872\n",
            "Epoch: 115/250 | Batch: 1/527 | Loss: 0.5600329637527466\n",
            "Epoch: 115/250 | Average Epoch Loss: 0.5418737225050718\n",
            "Epoch: 116/250 | Batch: 1/527 | Loss: 0.15712688863277435\n",
            "Epoch: 116/250 | Average Epoch Loss: 0.5502052303170344\n",
            "Epoch: 117/250 | Batch: 1/527 | Loss: 0.5401674509048462\n",
            "Epoch: 117/250 | Average Epoch Loss: 0.5424308569030925\n",
            "Epoch: 118/250 | Batch: 1/527 | Loss: 0.5294406414031982\n",
            "Epoch: 118/250 | Average Epoch Loss: 0.54789023429325\n",
            "Epoch: 119/250 | Batch: 1/527 | Loss: 0.18968439102172852\n",
            "Epoch: 119/250 | Average Epoch Loss: 0.5149070553523992\n",
            "Epoch: 120/250 | Batch: 1/527 | Loss: 0.1762542426586151\n",
            "Epoch: 120/250 | Average Epoch Loss: 0.5281353715022555\n",
            "Epoch: 121/250 | Batch: 1/527 | Loss: 0.5176123976707458\n",
            "Epoch: 121/250 | Average Epoch Loss: 0.5479239786937974\n",
            "Epoch: 122/250 | Batch: 1/527 | Loss: 1.2757272720336914\n",
            "Epoch: 122/250 | Average Epoch Loss: 0.5301821996692915\n",
            "Epoch: 123/250 | Batch: 1/527 | Loss: 0.5457213521003723\n",
            "Epoch: 123/250 | Average Epoch Loss: 0.535052865545709\n",
            "Epoch: 124/250 | Batch: 1/527 | Loss: 0.17192934453487396\n",
            "Epoch: 124/250 | Average Epoch Loss: 0.5295121049971463\n",
            "Epoch: 125/250 | Batch: 1/527 | Loss: 0.14548438787460327\n",
            "Epoch: 125/250 | Average Epoch Loss: 0.5224357388447086\n",
            "Epoch: 126/250 | Batch: 1/527 | Loss: 0.540969967842102\n",
            "Epoch: 126/250 | Average Epoch Loss: 0.5329444935471103\n",
            "Epoch: 127/250 | Batch: 1/527 | Loss: 0.17330904304981232\n",
            "Epoch: 127/250 | Average Epoch Loss: 0.5028732450682479\n",
            "Epoch: 128/250 | Batch: 1/527 | Loss: 0.8744050860404968\n",
            "Epoch: 128/250 | Average Epoch Loss: 0.5340743434440479\n",
            "Epoch: 129/250 | Batch: 1/527 | Loss: 0.5198289155960083\n",
            "Epoch: 129/250 | Average Epoch Loss: 0.5376000352331085\n",
            "Epoch: 130/250 | Batch: 1/527 | Loss: 0.16347123682498932\n",
            "Epoch: 130/250 | Average Epoch Loss: 0.5141500557792255\n",
            "Epoch: 131/250 | Batch: 1/527 | Loss: 0.5439677238464355\n",
            "Epoch: 131/250 | Average Epoch Loss: 0.525433984721182\n",
            "Epoch: 132/250 | Batch: 1/527 | Loss: 0.521460771560669\n",
            "Epoch: 132/250 | Average Epoch Loss: 0.5232368554121176\n",
            "Epoch: 133/250 | Batch: 1/527 | Loss: 0.535251796245575\n",
            "Epoch: 133/250 | Average Epoch Loss: 0.5210310268221137\n",
            "Epoch: 134/250 | Batch: 1/527 | Loss: 0.148401141166687\n",
            "Epoch: 134/250 | Average Epoch Loss: 0.5165613113250407\n",
            "Epoch: 135/250 | Batch: 1/527 | Loss: 0.16373129189014435\n",
            "Epoch: 135/250 | Average Epoch Loss: 0.5292552591388094\n",
            "Epoch: 136/250 | Batch: 1/527 | Loss: 1.248658537864685\n",
            "Epoch: 136/250 | Average Epoch Loss: 0.5242534676810596\n",
            "Epoch: 137/250 | Batch: 1/527 | Loss: 0.8889291882514954\n",
            "Epoch: 137/250 | Average Epoch Loss: 0.5339954523422686\n",
            "Epoch: 138/250 | Batch: 1/527 | Loss: 0.8930043578147888\n",
            "Epoch: 138/250 | Average Epoch Loss: 0.5208750831447471\n",
            "Epoch: 139/250 | Batch: 1/527 | Loss: 0.5052968859672546\n",
            "Epoch: 139/250 | Average Epoch Loss: 0.483737285862159\n",
            "Epoch: 140/250 | Batch: 1/527 | Loss: 0.5164647698402405\n",
            "Epoch: 140/250 | Average Epoch Loss: 0.4892548712878797\n",
            "Epoch: 141/250 | Batch: 1/527 | Loss: 0.14968128502368927\n",
            "Epoch: 141/250 | Average Epoch Loss: 0.5153451861364792\n",
            "Epoch: 142/250 | Batch: 1/527 | Loss: 0.5283218026161194\n",
            "Epoch: 142/250 | Average Epoch Loss: 0.5103403577259414\n",
            "Epoch: 143/250 | Batch: 1/527 | Loss: 0.8869867324829102\n",
            "Epoch: 143/250 | Average Epoch Loss: 0.4972874985361009\n",
            "Epoch: 144/250 | Batch: 1/527 | Loss: 0.15046706795692444\n"
          ]
        }
      ],
      "source": [
        "# train model\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "new_model_stats = model.train_model(loader=train_loader, optimizer=optimizer, criterion=criterion, epochs=200, print_every=1000)\n",
        "\n",
        "if model_stats is not None:\n",
        "    new_model_stats['epochs'] += model_stats['epochs']\n",
        "    new_model_stats['total_time'] += model_stats['total_time']\n",
        "    new_model_stats['losses'] = model_stats['losses'] + new_model_stats['losses']\n",
        "    new_model_stats['average_losses'] = model_stats['average_losses'] + new_model_stats['average_losses']\n",
        "\n",
        "torch.save(model_stats, \"standart.pt\")\n",
        "\n",
        "# load temp model\n",
        "temp_model_stats = torch.load(\"temp_model.pt\", map_location=torch.device(device))\n",
        "\n",
        "# compare losses\n",
        "if temp_model_stats['last_loss'] < model_stats['last_loss']:\n",
        "    # replace model structure\n",
        "    for key in temp_model_stats.keys():\n",
        "        model_stats[key] = temp_model_stats[key]\n",
        "    torch.save(model_stats, \"standart.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Bncn1u9GDP"
      },
      "source": [
        "# Evaluierung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HcRCpW29GDQ"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "    def __init__(self, model, dataloader, device):\n",
        "        # initiate variables \n",
        "        self.model = model\n",
        "        self.dataloader = dataloader\n",
        "        self.device = device\n",
        "        # self.model.eval()\n",
        "        # assert self.dataloader.batch_size == 1, \"Batch size must be 1 for evaluation.\"\n",
        "    \n",
        "    def evaluate(self):\n",
        "        scores = []\n",
        "\n",
        "        for i, (images, captions, lengths, vectorized_captions) in enumerate(self.dataloader):\n",
        "            # move to device\n",
        "            images = images.to(self.device)\n",
        "            captions = captions.to(self.device)\n",
        "            vectorized_captions = vectorized_captions.to(self.device)\n",
        "            \n",
        "            # forward pass\n",
        "            output = self.model.forward(images)\n",
        "            references = self.model.words[vectorized_captions.cpu()]\n",
        "\n",
        "            for j in range(output.shape[0]):\n",
        "                candidate = self.output_to_sentence(output[j,:])\n",
        "                reference = self.output_to_sentence(references[j,:])\n",
        "                scores.append(self.bleu_score(candidate, reference))\n",
        "            \n",
        "            print(f\"Batch: {i+1} of {len(self.dataloader)}\")\n",
        "\n",
        "        print(f\"Average BLEU score: {np.mean(scores)}\")\n",
        "        return np.mean(scores), scores\n",
        "\n",
        "    @staticmethod\n",
        "    def output_to_sentence(output:list):\n",
        "        '''\n",
        "        Removes Tokens from model output.\n",
        "        '''\n",
        "        output = [token for token in output if token not in [\"<SOS>\", \"<EOS>\", \"<PAD>\"]]\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def bleu_score(reference, candidate):\n",
        "        '''\n",
        "        Calculates the BLEU score for a single reference and candidate. Uses the SmoothingFunction for smoothing when no overlap between certain n-grams is found. \n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "        reference: list of strings - The reference sentence.\n",
        "        candidate: list of strings - The candidate sentence.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        bleu_score: float - The BLEU score.\n",
        "        '''\n",
        "        # calculate the BLEU score\n",
        "        return nltk.translate.bleu_score.sentence_bleu(reference, candidate, smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NttpE3AhHt1M"
      },
      "outputs": [],
      "source": [
        "path = 'standart.pt'\n",
        "model_stats = torch.load(path, map_location=device)\n",
        "model = load_captioning_model(model_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U331derr9GDR"
      },
      "outputs": [],
      "source": [
        "train_dataset = FlickrDataset(captions=training_data, embedding=embedding)\n",
        "test_dataset = FlickrDataset(captions=test_data, embedding=embedding)\n",
        "\n",
        "# create dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "\n",
        "# calculate bleu scores\n",
        "train_evaluator = Evaluator(model, train_loader, device)\n",
        "test_evaluator = Evaluator(model, test_loader, device)\n",
        "\n",
        "train_bleu, train_scores = train_evaluator.evaluate()\n",
        "test_bleu, test_scores = test_evaluator.evaluate()\n",
        "\n",
        "print(f\"Train BLEU: {train_bleu}\")\n",
        "print(f\"Test BLEU: {test_bleu}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7ggCETV9GDS"
      },
      "outputs": [],
      "source": [
        "# export bleu scores\n",
        "with open(\"standart_train_scores.pkl\", \"wb\") as f:\n",
        "    pickle.dump(train_scores, f)\n",
        "\n",
        "with open(\"standart_train_scores.pkl\", \"wb\") as f:\n",
        "    pickle.dump(test_scores, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.15 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "8c062c6b57d91616a29c64ccda85a992f94b9c302ff6b9e6bdfcfbfa090602a1"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ea2d7f30ded4b0aa661cd1b63da644a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5389d28534dd43a3af22a13e426effae",
            "placeholder": "​",
            "style": "IPY_MODEL_3b9ded511f9c46cd96e212cb0365269b",
            "value": "100%"
          }
        },
        "38247c71882a491fad78052adb334296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b9ded511f9c46cd96e212cb0365269b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5389d28534dd43a3af22a13e426effae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6b7d55bf3a486f89aa2fc407b3b3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70ad6c60af024efc86f26227c10303ab",
            "max": 100488385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d6bc20bd45845ea93ba03b01737623f",
            "value": 100488385
          }
        },
        "70ad6c60af024efc86f26227c10303ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6bc20bd45845ea93ba03b01737623f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ebf7b02ecb74a319762bbb212a1645a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fff5a57e9f34b59bb4e69be3cc04e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ea2d7f30ded4b0aa661cd1b63da644a",
              "IPY_MODEL_6f6b7d55bf3a486f89aa2fc407b3b3e2",
              "IPY_MODEL_dd109543e2c54b53b82e38c9b5e9da44"
            ],
            "layout": "IPY_MODEL_cb539266fc76422d89dea25f7e1ed012"
          }
        },
        "cb539266fc76422d89dea25f7e1ed012": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd109543e2c54b53b82e38c9b5e9da44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ebf7b02ecb74a319762bbb212a1645a",
            "placeholder": "​",
            "style": "IPY_MODEL_38247c71882a491fad78052adb334296",
            "value": " 95.8M/95.8M [00:03&lt;00:00, 40.5MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
