{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "23FSvPla9GDC"
      },
      "outputs": [],
      "source": [
        "# import python file from parent folder\n",
        "from img_cap_lib import *\n",
        "# imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torchtext\n",
        "from torchtext.vocab import vocab, GloVe, Vectors\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import os\n",
        "from PIL import Image\n",
        "import string\n",
        "from collections import OrderedDict, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import os\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFpN7FJu9Kd8",
        "outputId": "3dc03378-cda9-4a38-ff76-b0f86c956fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImcPlOrB9GDG"
      },
      "source": [
        "# Daten herunterladen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or3FdVAM9GDH",
        "outputId": "7dd3ddb2-e222-44cd-b4a2-aedbfae22b29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data already exi sts at flickr8k\n"
          ]
        }
      ],
      "source": [
        "data_download(\"flickr8k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZovGtMKV9GDK"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdgY3n_J9GDK",
        "outputId": "87e81b40-e667-4b8b-c2a8-608bc0f821d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape captions: (40460, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape captions after filtering: (39749, 3)\n",
            "Removed Captions:  711 , in Percent:  1.76\n",
            "transformed_images folder already exists. No preprocessing necessary.\n"
          ]
        }
      ],
      "source": [
        "# caption preprocessing\n",
        "embedding_dim = 300\n",
        "min_frequency = 1\n",
        "\n",
        "captions = pd.read_csv(\"flickr8k/captions.txt\")\n",
        "caption_preprocessor = CaptionPreprocessor(captions=captions, embedding_dim=embedding_dim, min_frequency=min_frequency)\n",
        "caption_preprocessor.preprocess()\n",
        "\n",
        "# image preprocessing\n",
        "img_preprocessor = ImagePreprocessor(normalize=True, image_folder_path=\"flickr8k\")\n",
        "img_preprocessor.preprocess_images()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nl3NT_K9GDL"
      },
      "source": [
        "# Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aQ07VI9R9GDM"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "training_data, test_data = train_test_split(caption_preprocessor.captions, test_size=0.15, random_state=42)\n",
        "\n",
        "embedding = Embedding(embedding_matrix=caption_preprocessor.embedding, vocabulary=caption_preprocessor.vocabulary)\n",
        "\n",
        "# create dataset\n",
        "train_dataset = FlickrDataset(captions=training_data, embedding=embedding)\n",
        "test_dataset = FlickrDataset(captions=test_data, embedding=embedding)\n",
        "\n",
        "# create dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-254t2-t9GDN"
      },
      "source": [
        "# Modell erstellen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8MBnXU09GDN"
      },
      "outputs": [],
      "source": [
        "encoder = EncoderCNN(net=torchvision.models.resnext50_32x4d, pretrained_weights=torchvision.models.ResNeXt50_32X4D_Weights.IMAGENET1K_V2, output_size=300)\n",
        "decoder = DecoderRNN(input_size=300, hidden_size=caption_preprocessor.embedding_dim, num_layers=1, dropout=0.0, len_vocab=embedding.embedding_matrix.shape[0], len_subtract=0)\n",
        "\n",
        "model = ImageCaptioning(encoder=encoder, decoder=decoder, embedding=embedding, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02luogN-9GDO",
        "outputId": "59f326db-fff1-408b-b9bf-458e30175737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/250 | Batch: 1/527 | Loss: 8.97307014465332\n",
            "Epoch: 1/250 | Average Epoch Loss: 7.0130262908718395\n",
            "Epoch: 2/250 | Batch: 1/527 | Loss: 6.673590183258057\n",
            "Epoch: 2/250 | Average Epoch Loss: 6.482943236262342\n",
            "Epoch: 3/250 | Batch: 1/527 | Loss: 6.243509292602539\n",
            "Epoch: 3/250 | Average Epoch Loss: 6.282781223644568\n",
            "Epoch: 4/250 | Batch: 1/527 | Loss: 6.2735137939453125\n",
            "Epoch: 4/250 | Average Epoch Loss: 6.127988313135657\n",
            "Epoch: 5/250 | Batch: 1/527 | Loss: 6.0735249519348145\n",
            "Epoch: 5/250 | Average Epoch Loss: 6.000287556331569\n",
            "Epoch: 6/250 | Batch: 1/527 | Loss: 5.871740818023682\n",
            "Epoch: 6/250 | Average Epoch Loss: 5.891066057179866\n",
            "Epoch: 7/250 | Batch: 1/527 | Loss: 5.835323810577393\n",
            "Epoch: 7/250 | Average Epoch Loss: 5.7913342436079285\n",
            "Epoch: 8/250 | Batch: 1/527 | Loss: 5.660100936889648\n",
            "Epoch: 8/250 | Average Epoch Loss: 5.701445124407194\n",
            "Epoch: 9/250 | Batch: 1/527 | Loss: 5.768121719360352\n",
            "Epoch: 9/250 | Average Epoch Loss: 5.617565630056826\n",
            "Epoch: 10/250 | Batch: 1/527 | Loss: 5.548180103302002\n",
            "Epoch: 10/250 | Average Epoch Loss: 5.538798083390412\n",
            "Epoch: 11/250 | Batch: 1/527 | Loss: 5.637386798858643\n",
            "Epoch: 11/250 | Average Epoch Loss: 5.464975581449621\n",
            "Epoch: 12/250 | Batch: 1/527 | Loss: 5.325587272644043\n",
            "Epoch: 12/250 | Average Epoch Loss: 5.395338148953114\n",
            "Epoch: 13/250 | Batch: 1/527 | Loss: 5.452564716339111\n",
            "Epoch: 13/250 | Average Epoch Loss: 5.328219833591179\n",
            "Epoch: 14/250 | Batch: 1/527 | Loss: 5.342388153076172\n",
            "Epoch: 14/250 | Average Epoch Loss: 5.2642607752240815\n",
            "Epoch: 15/250 | Batch: 1/527 | Loss: 5.371570110321045\n",
            "Epoch: 15/250 | Average Epoch Loss: 5.202679120159692\n",
            "Epoch: 16/250 | Batch: 1/527 | Loss: 5.127318859100342\n",
            "Epoch: 16/250 | Average Epoch Loss: 5.1418997938311755\n",
            "Epoch: 17/250 | Batch: 1/527 | Loss: 5.16706657409668\n",
            "Epoch: 17/250 | Average Epoch Loss: 5.082567558795271\n",
            "Epoch: 18/250 | Batch: 1/527 | Loss: 5.2795023918151855\n",
            "Epoch: 18/250 | Average Epoch Loss: 5.025694451703066\n",
            "Epoch: 19/250 | Batch: 1/527 | Loss: 4.890446186065674\n",
            "Epoch: 19/250 | Average Epoch Loss: 4.970334902660218\n",
            "Epoch: 20/250 | Batch: 1/527 | Loss: 4.892541885375977\n",
            "Epoch: 20/250 | Average Epoch Loss: 4.916401582605698\n",
            "Epoch: 21/250 | Batch: 1/527 | Loss: 4.948568344116211\n",
            "Epoch: 21/250 | Average Epoch Loss: 4.861930517815548\n",
            "Epoch: 22/250 | Batch: 1/527 | Loss: 4.665842056274414\n",
            "Epoch: 22/250 | Average Epoch Loss: 4.807552963778009\n",
            "Epoch: 23/250 | Batch: 1/527 | Loss: 4.574065685272217\n",
            "Epoch: 23/250 | Average Epoch Loss: 4.756796872140787\n",
            "Epoch: 24/250 | Batch: 1/527 | Loss: 4.9072184562683105\n",
            "Epoch: 24/250 | Average Epoch Loss: 4.70754499634484\n",
            "Epoch: 25/250 | Batch: 1/527 | Loss: 4.770630836486816\n",
            "Epoch: 25/250 | Average Epoch Loss: 4.658481757147714\n",
            "Epoch: 26/250 | Batch: 1/527 | Loss: 4.659687519073486\n",
            "Epoch: 26/250 | Average Epoch Loss: 4.606545559595387\n",
            "Epoch: 27/250 | Batch: 1/527 | Loss: 4.466081619262695\n",
            "Epoch: 27/250 | Average Epoch Loss: 4.558377109397295\n",
            "Epoch: 28/250 | Batch: 1/527 | Loss: 4.514509201049805\n",
            "Epoch: 28/250 | Average Epoch Loss: 4.508892449301153\n",
            "Epoch: 29/250 | Batch: 1/527 | Loss: 4.356353282928467\n",
            "Epoch: 29/250 | Average Epoch Loss: 4.459182896695508\n",
            "Epoch: 30/250 | Batch: 1/527 | Loss: 4.351256847381592\n",
            "Epoch: 30/250 | Average Epoch Loss: 4.417355309401336\n",
            "Epoch: 31/250 | Batch: 1/527 | Loss: 4.302955150604248\n",
            "Epoch: 31/250 | Average Epoch Loss: 4.366485467219489\n",
            "Epoch: 32/250 | Batch: 1/527 | Loss: 4.154510498046875\n",
            "Epoch: 32/250 | Average Epoch Loss: 4.3203345824464225\n",
            "Epoch: 33/250 | Batch: 1/527 | Loss: 4.324772357940674\n",
            "Epoch: 33/250 | Average Epoch Loss: 4.27700693964732\n",
            "Epoch: 34/250 | Batch: 1/527 | Loss: 4.413343906402588\n",
            "Epoch: 34/250 | Average Epoch Loss: 4.22573141626434\n",
            "Epoch: 35/250 | Batch: 1/527 | Loss: 4.204826354980469\n",
            "Epoch: 35/250 | Average Epoch Loss: 4.183847881132556\n",
            "Epoch: 36/250 | Batch: 1/527 | Loss: 4.167539596557617\n",
            "Epoch: 36/250 | Average Epoch Loss: 4.1392057362724755\n",
            "Epoch: 37/250 | Batch: 1/527 | Loss: 4.196341514587402\n",
            "Epoch: 37/250 | Average Epoch Loss: 4.09369262210332\n",
            "Epoch: 38/250 | Batch: 1/527 | Loss: 4.278139114379883\n",
            "Epoch: 38/250 | Average Epoch Loss: 4.055619822959972\n",
            "Epoch: 39/250 | Batch: 1/527 | Loss: 3.958359479904175\n",
            "Epoch: 39/250 | Average Epoch Loss: 4.005872104380569\n",
            "Epoch: 40/250 | Batch: 1/527 | Loss: 4.219668865203857\n",
            "Epoch: 40/250 | Average Epoch Loss: 3.959143286638061\n",
            "Epoch: 41/250 | Batch: 1/527 | Loss: 4.070947170257568\n",
            "Epoch: 41/250 | Average Epoch Loss: 3.9153262541913896\n",
            "Epoch: 42/250 | Batch: 1/527 | Loss: 4.00671911239624\n",
            "Epoch: 42/250 | Average Epoch Loss: 3.8756978588719524\n",
            "Epoch: 43/250 | Batch: 1/527 | Loss: 3.9175591468811035\n",
            "Epoch: 43/250 | Average Epoch Loss: 3.8276251859863977\n",
            "Epoch: 44/250 | Batch: 1/527 | Loss: 3.6585097312927246\n",
            "Epoch: 44/250 | Average Epoch Loss: 3.787390299947257\n",
            "Epoch: 45/250 | Batch: 1/527 | Loss: 3.7710466384887695\n",
            "Epoch: 45/250 | Average Epoch Loss: 3.7474456932784483\n",
            "Epoch: 46/250 | Batch: 1/527 | Loss: 3.896787405014038\n",
            "Epoch: 46/250 | Average Epoch Loss: 3.7054085478158334\n",
            "Epoch: 47/250 | Batch: 1/527 | Loss: 3.6250991821289062\n",
            "Epoch: 47/250 | Average Epoch Loss: 3.6673999936576136\n",
            "Epoch: 48/250 | Batch: 1/527 | Loss: 3.3403992652893066\n",
            "Epoch: 48/250 | Average Epoch Loss: 3.619777625154499\n",
            "Epoch: 49/250 | Batch: 1/527 | Loss: 3.903642177581787\n",
            "Epoch: 49/250 | Average Epoch Loss: 3.5849966405691185\n",
            "Epoch: 50/250 | Batch: 1/527 | Loss: 3.7025039196014404\n",
            "Epoch: 50/250 | Average Epoch Loss: 3.5453515428293363\n",
            "Epoch: 51/250 | Batch: 1/527 | Loss: 3.308983564376831\n",
            "Epoch: 51/250 | Average Epoch Loss: 3.4955799909877596\n",
            "Epoch: 52/250 | Batch: 1/527 | Loss: 3.4637458324432373\n",
            "Epoch: 52/250 | Average Epoch Loss: 3.4532642853101696\n",
            "Epoch: 53/250 | Batch: 1/527 | Loss: 3.5541419982910156\n",
            "Epoch: 53/250 | Average Epoch Loss: 3.413445975794059\n",
            "Epoch: 54/250 | Batch: 1/527 | Loss: 3.3290412425994873\n",
            "Epoch: 54/250 | Average Epoch Loss: 3.3771276790684044\n",
            "Epoch: 55/250 | Batch: 1/527 | Loss: 3.163633108139038\n",
            "Epoch: 55/250 | Average Epoch Loss: 3.336430787587754\n",
            "Epoch: 56/250 | Batch: 1/527 | Loss: 3.575550079345703\n",
            "Epoch: 56/250 | Average Epoch Loss: 3.2988828522430653\n",
            "Epoch: 57/250 | Batch: 1/527 | Loss: 3.063102960586548\n",
            "Epoch: 57/250 | Average Epoch Loss: 3.2488025126013858\n",
            "Epoch: 58/250 | Batch: 1/527 | Loss: 3.184539794921875\n",
            "Epoch: 58/250 | Average Epoch Loss: 3.22155214803721\n",
            "Epoch: 59/250 | Batch: 1/527 | Loss: 3.0361640453338623\n",
            "Epoch: 59/250 | Average Epoch Loss: 3.1769774855879724\n",
            "Epoch: 60/250 | Batch: 1/527 | Loss: 3.132366895675659\n",
            "Epoch: 60/250 | Average Epoch Loss: 3.134746289117513\n",
            "Epoch: 61/250 | Batch: 1/527 | Loss: 2.938124895095825\n",
            "Epoch: 61/250 | Average Epoch Loss: 3.094398931488819\n",
            "Epoch: 62/250 | Batch: 1/527 | Loss: 3.5001466274261475\n",
            "Epoch: 62/250 | Average Epoch Loss: 3.0719837762372997\n",
            "Epoch: 63/250 | Batch: 1/527 | Loss: 3.0837485790252686\n",
            "Epoch: 63/250 | Average Epoch Loss: 3.015252107460992\n",
            "Epoch: 64/250 | Batch: 1/527 | Loss: 2.6559481620788574\n",
            "Epoch: 64/250 | Average Epoch Loss: 2.977927485272373\n",
            "Epoch: 65/250 | Batch: 1/527 | Loss: 2.6648855209350586\n",
            "Epoch: 65/250 | Average Epoch Loss: 2.9398953254127864\n",
            "Epoch: 66/250 | Batch: 1/527 | Loss: 2.665010452270508\n",
            "Epoch: 66/250 | Average Epoch Loss: 2.914809804713703\n",
            "Epoch: 67/250 | Batch: 1/527 | Loss: 2.85294508934021\n",
            "Epoch: 67/250 | Average Epoch Loss: 2.861813341643824\n",
            "Epoch: 68/250 | Batch: 1/527 | Loss: 2.9646904468536377\n",
            "Epoch: 68/250 | Average Epoch Loss: 2.832965504286185\n",
            "Epoch: 69/250 | Batch: 1/527 | Loss: 2.6237096786499023\n",
            "Epoch: 69/250 | Average Epoch Loss: 2.791382196506015\n",
            "Epoch: 70/250 | Batch: 1/527 | Loss: 2.5916237831115723\n",
            "Epoch: 70/250 | Average Epoch Loss: 2.7546293667643074\n",
            "Epoch: 71/250 | Batch: 1/527 | Loss: 2.56839919090271\n",
            "Epoch: 71/250 | Average Epoch Loss: 2.723677995761386\n",
            "Epoch: 72/250 | Batch: 1/527 | Loss: 2.899322748184204\n",
            "Epoch: 72/250 | Average Epoch Loss: 2.695949124656547\n",
            "Epoch: 73/250 | Batch: 1/527 | Loss: 3.1313295364379883\n",
            "Epoch: 73/250 | Average Epoch Loss: 2.6472788490425705\n",
            "Epoch: 74/250 | Batch: 1/527 | Loss: 3.175539970397949\n",
            "Epoch: 74/250 | Average Epoch Loss: 2.6258347296850504\n",
            "Epoch: 75/250 | Batch: 1/527 | Loss: 2.334510564804077\n",
            "Epoch: 75/250 | Average Epoch Loss: 2.5665344739548397\n",
            "Epoch: 76/250 | Batch: 1/527 | Loss: 2.294220209121704\n",
            "Epoch: 76/250 | Average Epoch Loss: 2.5393604951746322\n",
            "Epoch: 77/250 | Batch: 1/527 | Loss: 2.2335493564605713\n",
            "Epoch: 77/250 | Average Epoch Loss: 2.5163180484265033\n",
            "Epoch: 78/250 | Batch: 1/527 | Loss: 2.8069796562194824\n",
            "Epoch: 78/250 | Average Epoch Loss: 2.4686319832557517\n",
            "Epoch: 79/250 | Batch: 1/527 | Loss: 2.230222463607788\n",
            "Epoch: 79/250 | Average Epoch Loss: 2.4335275424725644\n",
            "Epoch: 80/250 | Batch: 1/527 | Loss: 2.3899919986724854\n",
            "Epoch: 80/250 | Average Epoch Loss: 2.4065116732125036\n",
            "Epoch: 81/250 | Batch: 1/527 | Loss: 2.2970056533813477\n",
            "Epoch: 81/250 | Average Epoch Loss: 2.3797756218593533\n",
            "Epoch: 82/250 | Batch: 1/527 | Loss: 2.1442360877990723\n",
            "Epoch: 82/250 | Average Epoch Loss: 2.3367497138325586\n",
            "Epoch: 83/250 | Batch: 1/527 | Loss: 2.031507730484009\n",
            "Epoch: 83/250 | Average Epoch Loss: 2.3030463647118555\n",
            "Epoch: 84/250 | Batch: 1/527 | Loss: 1.945090413093567\n",
            "Epoch: 84/250 | Average Epoch Loss: 2.2782110851222694\n",
            "Epoch: 85/250 | Batch: 1/527 | Loss: 2.513375759124756\n",
            "Epoch: 85/250 | Average Epoch Loss: 2.2449060839086603\n",
            "Epoch: 86/250 | Batch: 1/527 | Loss: 2.2434914112091064\n",
            "Epoch: 86/250 | Average Epoch Loss: 2.2195994668486447\n",
            "Epoch: 87/250 | Batch: 1/527 | Loss: 2.23252010345459\n",
            "Epoch: 87/250 | Average Epoch Loss: 2.1995486738107237\n",
            "Epoch: 88/250 | Batch: 1/527 | Loss: 1.9315154552459717\n",
            "Epoch: 88/250 | Average Epoch Loss: 2.1513424046351743\n",
            "Epoch: 89/250 | Batch: 1/527 | Loss: 2.3664629459381104\n",
            "Epoch: 89/250 | Average Epoch Loss: 2.1162437578306252\n",
            "Epoch: 90/250 | Batch: 1/527 | Loss: 2.0638136863708496\n",
            "Epoch: 90/250 | Average Epoch Loss: 2.103699405460249\n",
            "Epoch: 91/250 | Batch: 1/527 | Loss: 1.8016985654830933\n",
            "Epoch: 91/250 | Average Epoch Loss: 2.0625418012915797\n",
            "Epoch: 92/250 | Batch: 1/527 | Loss: 1.759172797203064\n",
            "Epoch: 92/250 | Average Epoch Loss: 2.035720279366061\n",
            "Epoch: 93/250 | Batch: 1/527 | Loss: 1.9883205890655518\n",
            "Epoch: 93/250 | Average Epoch Loss: 2.0099037464927223\n",
            "Epoch: 94/250 | Batch: 1/527 | Loss: 2.2576494216918945\n",
            "Epoch: 94/250 | Average Epoch Loss: 1.9902807623430718\n",
            "Epoch: 95/250 | Batch: 1/527 | Loss: 1.6729629039764404\n",
            "Epoch: 95/250 | Average Epoch Loss: 1.9776855960516595\n",
            "Epoch: 96/250 | Batch: 1/527 | Loss: 1.6388188600540161\n",
            "Epoch: 96/250 | Average Epoch Loss: 1.9243472491088809\n",
            "Epoch: 97/250 | Batch: 1/527 | Loss: 1.9324179887771606\n",
            "Epoch: 97/250 | Average Epoch Loss: 1.909682949534856\n",
            "Epoch: 98/250 | Batch: 1/527 | Loss: 1.9145424365997314\n",
            "Epoch: 98/250 | Average Epoch Loss: 1.872721960920084\n",
            "Epoch: 99/250 | Batch: 1/527 | Loss: 1.5439693927764893\n",
            "Epoch: 99/250 | Average Epoch Loss: 1.8663561384863374\n",
            "Epoch: 100/250 | Batch: 1/527 | Loss: 1.5582081079483032\n",
            "Epoch: 100/250 | Average Epoch Loss: 1.8203649290146366\n",
            "Epoch: 101/250 | Batch: 1/527 | Loss: 2.1096208095550537\n",
            "Epoch: 101/250 | Average Epoch Loss: 1.8121897350904836\n",
            "Epoch: 102/250 | Batch: 1/527 | Loss: 2.418800115585327\n",
            "Epoch: 102/250 | Average Epoch Loss: 1.7827526263086801\n",
            "Epoch: 103/250 | Batch: 1/527 | Loss: 1.751236081123352\n",
            "Epoch: 103/250 | Average Epoch Loss: 1.7524698945557595\n",
            "Epoch: 104/250 | Batch: 1/527 | Loss: 1.4473004341125488\n",
            "Epoch: 104/250 | Average Epoch Loss: 1.7484695793781606\n",
            "Epoch: 105/250 | Batch: 1/527 | Loss: 2.0086634159088135\n",
            "Epoch: 105/250 | Average Epoch Loss: 1.7175751883798125\n",
            "Epoch: 106/250 | Batch: 1/527 | Loss: 1.4162298440933228\n",
            "Epoch: 106/250 | Average Epoch Loss: 1.6836010251597164\n",
            "Epoch: 107/250 | Batch: 1/527 | Loss: 1.6893948316574097\n",
            "Epoch: 107/250 | Average Epoch Loss: 1.6648695050425955\n",
            "Epoch: 108/250 | Batch: 1/527 | Loss: 1.7064571380615234\n",
            "Epoch: 108/250 | Average Epoch Loss: 1.666652720612412\n",
            "Epoch: 109/250 | Batch: 1/527 | Loss: 1.6234703063964844\n",
            "Epoch: 109/250 | Average Epoch Loss: 1.6480673918009257\n",
            "Epoch: 110/250 | Batch: 1/527 | Loss: 1.2921656370162964\n",
            "Epoch: 110/250 | Average Epoch Loss: 1.612928699723231\n",
            "Epoch: 111/250 | Batch: 1/527 | Loss: 1.2830853462219238\n",
            "Epoch: 111/250 | Average Epoch Loss: 1.6162094253290311\n",
            "Epoch: 112/250 | Batch: 1/527 | Loss: 1.3050612211227417\n",
            "Epoch: 112/250 | Average Epoch Loss: 1.5742416404456296\n",
            "Epoch: 113/250 | Batch: 1/527 | Loss: 1.2407069206237793\n",
            "Epoch: 113/250 | Average Epoch Loss: 1.5755844514329247\n",
            "Epoch: 114/250 | Batch: 1/527 | Loss: 1.2204844951629639\n",
            "Epoch: 114/250 | Average Epoch Loss: 1.5619370849128014\n",
            "Epoch: 115/250 | Batch: 1/527 | Loss: 1.2136330604553223\n",
            "Epoch: 115/250 | Average Epoch Loss: 1.562292788015145\n",
            "Epoch: 116/250 | Batch: 1/527 | Loss: 1.5385348796844482\n",
            "Epoch: 116/250 | Average Epoch Loss: 1.5352049588704697\n",
            "Epoch: 117/250 | Batch: 1/527 | Loss: 1.8633792400360107\n",
            "Epoch: 117/250 | Average Epoch Loss: 1.5117321118457947\n",
            "Epoch: 118/250 | Batch: 1/527 | Loss: 1.5295902490615845\n",
            "Epoch: 118/250 | Average Epoch Loss: 1.5175180408036233\n",
            "Epoch: 119/250 | Batch: 1/527 | Loss: 1.512764811515808\n",
            "Epoch: 119/250 | Average Epoch Loss: 1.4956352484520292\n",
            "Epoch: 120/250 | Batch: 1/527 | Loss: 1.7969226837158203\n",
            "Epoch: 120/250 | Average Epoch Loss: 1.4636634382396314\n",
            "Epoch: 121/250 | Batch: 1/527 | Loss: 1.475592017173767\n",
            "Epoch: 121/250 | Average Epoch Loss: 1.446062415555487\n",
            "Epoch: 122/250 | Batch: 1/527 | Loss: 1.799814224243164\n",
            "Epoch: 122/250 | Average Epoch Loss: 1.4554245426713628\n",
            "Epoch: 123/250 | Batch: 1/527 | Loss: 1.7852141857147217\n",
            "Epoch: 123/250 | Average Epoch Loss: 1.4322960654969912\n",
            "Epoch: 124/250 | Batch: 1/527 | Loss: 1.760205864906311\n",
            "Epoch: 124/250 | Average Epoch Loss: 1.4349311336846686\n",
            "Epoch: 125/250 | Batch: 1/527 | Loss: 1.0588105916976929\n",
            "Epoch: 125/250 | Average Epoch Loss: 1.4119812008099493\n",
            "Epoch: 126/250 | Batch: 1/527 | Loss: 1.4105167388916016\n",
            "Epoch: 126/250 | Average Epoch Loss: 1.4072270327772542\n",
            "Epoch: 127/250 | Batch: 1/527 | Loss: 1.082260251045227\n",
            "Epoch: 127/250 | Average Epoch Loss: 1.3899020589958784\n",
            "Epoch: 128/250 | Batch: 1/527 | Loss: 1.7620660066604614\n",
            "Epoch: 128/250 | Average Epoch Loss: 1.3713910855649771\n",
            "Epoch: 129/250 | Batch: 1/527 | Loss: 1.409907579421997\n",
            "Epoch: 129/250 | Average Epoch Loss: 1.375319505552187\n",
            "Epoch: 130/250 | Batch: 1/527 | Loss: 1.7286254167556763\n",
            "Epoch: 130/250 | Average Epoch Loss: 1.3784707432906134\n",
            "Epoch: 131/250 | Batch: 1/527 | Loss: 1.7157676219940186\n",
            "Epoch: 131/250 | Average Epoch Loss: 1.3720874647261747\n",
            "Epoch: 132/250 | Batch: 1/527 | Loss: 1.3408446311950684\n",
            "Epoch: 132/250 | Average Epoch Loss: 1.349802877803455\n",
            "Epoch: 133/250 | Batch: 1/527 | Loss: 1.6808419227600098\n",
            "Epoch: 133/250 | Average Epoch Loss: 1.356688240108273\n",
            "Epoch: 134/250 | Batch: 1/527 | Loss: 1.0232338905334473\n",
            "Epoch: 134/250 | Average Epoch Loss: 1.3487251287845778\n",
            "Epoch: 135/250 | Batch: 1/527 | Loss: 1.3345534801483154\n",
            "Epoch: 135/250 | Average Epoch Loss: 1.3350401406496255\n",
            "Epoch: 136/250 | Batch: 1/527 | Loss: 1.330228328704834\n",
            "Epoch: 136/250 | Average Epoch Loss: 1.3363064380479266\n",
            "Epoch: 137/250 | Batch: 1/527 | Loss: 0.9796798229217529\n",
            "Epoch: 137/250 | Average Epoch Loss: 1.309874316659779\n",
            "Epoch: 138/250 | Batch: 1/527 | Loss: 1.331743597984314\n",
            "Epoch: 138/250 | Average Epoch Loss: 1.3008422059849951\n",
            "Epoch: 139/250 | Batch: 1/527 | Loss: 1.3007937669754028\n",
            "Epoch: 139/250 | Average Epoch Loss: 1.2910648471264052\n",
            "Epoch: 140/250 | Batch: 1/527 | Loss: 1.3011056184768677\n",
            "Epoch: 140/250 | Average Epoch Loss: 1.2921417679008542\n",
            "Epoch: 141/250 | Batch: 1/527 | Loss: 0.9783787131309509\n",
            "Epoch: 141/250 | Average Epoch Loss: 1.2864346325510594\n",
            "Epoch: 142/250 | Batch: 1/527 | Loss: 1.6334322690963745\n",
            "Epoch: 142/250 | Average Epoch Loss: 1.2616977803621165\n",
            "Epoch: 143/250 | Batch: 1/527 | Loss: 1.262974739074707\n",
            "Epoch: 143/250 | Average Epoch Loss: 1.275142779499575\n",
            "Epoch: 144/250 | Batch: 1/527 | Loss: 0.9478518962860107\n",
            "Epoch: 144/250 | Average Epoch Loss: 1.2743074389517421\n",
            "Epoch: 145/250 | Batch: 1/527 | Loss: 1.9989094734191895\n",
            "Epoch: 145/250 | Average Epoch Loss: 1.2693844543914867\n",
            "Epoch: 146/250 | Batch: 1/527 | Loss: 1.9822673797607422\n",
            "Epoch: 146/250 | Average Epoch Loss: 1.2701171356088974\n",
            "Epoch: 147/250 | Batch: 1/527 | Loss: 0.8706172704696655\n",
            "Epoch: 147/250 | Average Epoch Loss: 1.2542880072313196\n",
            "Epoch: 148/250 | Batch: 1/527 | Loss: 1.2505446672439575\n",
            "Epoch: 148/250 | Average Epoch Loss: 1.244624364308207\n",
            "Epoch: 149/250 | Batch: 1/527 | Loss: 2.007240056991577\n",
            "Epoch: 149/250 | Average Epoch Loss: 1.24382348067394\n",
            "Epoch: 150/250 | Batch: 1/527 | Loss: 0.8531808257102966\n",
            "Epoch: 150/250 | Average Epoch Loss: 1.2330324534446961\n",
            "Epoch: 151/250 | Batch: 1/527 | Loss: 0.8958459496498108\n",
            "Epoch: 151/250 | Average Epoch Loss: 1.2463889433039208\n",
            "Epoch: 152/250 | Batch: 1/527 | Loss: 0.8870113492012024\n",
            "Epoch: 152/250 | Average Epoch Loss: 1.2501937668961411\n",
            "Epoch: 153/250 | Batch: 1/527 | Loss: 0.8809175491333008\n",
            "Epoch: 153/250 | Average Epoch Loss: 1.2277654902532387\n",
            "Epoch: 154/250 | Batch: 1/527 | Loss: 0.9002037048339844\n",
            "Epoch: 154/250 | Average Epoch Loss: 1.2279117012385852\n",
            "Epoch: 155/250 | Batch: 1/527 | Loss: 0.9131351709365845\n",
            "Epoch: 155/250 | Average Epoch Loss: 1.228905232061245\n",
            "Epoch: 156/250 | Batch: 1/527 | Loss: 0.8948624134063721\n",
            "Epoch: 156/250 | Average Epoch Loss: 1.2222389889849206\n",
            "Epoch: 157/250 | Batch: 1/527 | Loss: 0.8452603816986084\n",
            "Epoch: 157/250 | Average Epoch Loss: 1.2048213519226667\n",
            "Epoch: 158/250 | Batch: 1/527 | Loss: 0.8668482303619385\n",
            "Epoch: 158/250 | Average Epoch Loss: 1.2005889389727555\n",
            "Epoch: 159/250 | Batch: 1/527 | Loss: 1.2132192850112915\n",
            "Epoch: 159/250 | Average Epoch Loss: 1.2075243392072095\n",
            "Epoch: 160/250 | Batch: 1/527 | Loss: 1.94913911819458\n",
            "Epoch: 160/250 | Average Epoch Loss: 1.2169322217664411\n",
            "Epoch: 161/250 | Batch: 1/527 | Loss: 2.275266408920288\n",
            "Epoch: 161/250 | Average Epoch Loss: 1.1916415324925924\n",
            "Epoch: 162/250 | Batch: 1/527 | Loss: 1.1918765306472778\n",
            "Epoch: 162/250 | Average Epoch Loss: 1.1951054526913552\n",
            "Epoch: 163/250 | Batch: 1/527 | Loss: 1.887959361076355\n",
            "Epoch: 163/250 | Average Epoch Loss: 1.191802074266792\n",
            "Epoch: 164/250 | Batch: 1/527 | Loss: 1.207435965538025\n",
            "Epoch: 164/250 | Average Epoch Loss: 1.1968258137494834\n",
            "Epoch: 165/250 | Batch: 1/527 | Loss: 1.2067675590515137\n",
            "Epoch: 165/250 | Average Epoch Loss: 1.164512536444293\n",
            "Epoch: 166/250 | Batch: 1/527 | Loss: 1.1869738101959229\n",
            "Epoch: 166/250 | Average Epoch Loss: 1.1718920367492445\n",
            "Epoch: 167/250 | Batch: 1/527 | Loss: 0.8511831164360046\n",
            "Epoch: 167/250 | Average Epoch Loss: 1.172520838833398\n",
            "Epoch: 168/250 | Batch: 1/527 | Loss: 1.519344449043274\n",
            "Epoch: 168/250 | Average Epoch Loss: 1.186457911750171\n",
            "Epoch: 169/250 | Batch: 1/527 | Loss: 1.2120919227600098\n",
            "Epoch: 169/250 | Average Epoch Loss: 1.1689588009067007\n",
            "Epoch: 170/250 | Batch: 1/527 | Loss: 0.8193368911743164\n",
            "Epoch: 170/250 | Average Epoch Loss: 1.1875410135375932\n",
            "Epoch: 171/250 | Batch: 1/527 | Loss: 1.1730992794036865\n",
            "Epoch: 171/250 | Average Epoch Loss: 1.1625975770787451\n",
            "Epoch: 172/250 | Batch: 1/527 | Loss: 1.1648123264312744\n",
            "Epoch: 172/250 | Average Epoch Loss: 1.1532495035392283\n",
            "Epoch: 173/250 | Batch: 1/527 | Loss: 1.1463549137115479\n",
            "Epoch: 173/250 | Average Epoch Loss: 1.1343370150117313\n",
            "Epoch: 174/250 | Batch: 1/527 | Loss: 1.164145827293396\n",
            "Epoch: 174/250 | Average Epoch Loss: 1.1684128049428821\n",
            "Epoch: 175/250 | Batch: 1/527 | Loss: 1.1857199668884277\n",
            "Epoch: 175/250 | Average Epoch Loss: 1.139666026185993\n",
            "Epoch: 176/250 | Batch: 1/527 | Loss: 1.5617077350616455\n",
            "Epoch: 176/250 | Average Epoch Loss: 1.1467026570490235\n",
            "Epoch: 177/250 | Batch: 1/527 | Loss: 1.1675724983215332\n",
            "Epoch: 177/250 | Average Epoch Loss: 1.1504627888071468\n",
            "Epoch: 178/250 | Batch: 1/527 | Loss: 1.1671037673950195\n",
            "Epoch: 178/250 | Average Epoch Loss: 1.135556310358717\n",
            "Epoch: 179/250 | Batch: 1/527 | Loss: 1.1595790386199951\n",
            "Epoch: 179/250 | Average Epoch Loss: 1.1432604756934366\n",
            "Epoch: 180/250 | Batch: 1/527 | Loss: 0.7834712862968445\n",
            "Epoch: 180/250 | Average Epoch Loss: 1.1368372967392488\n",
            "Epoch: 181/250 | Batch: 1/527 | Loss: 0.7896307110786438\n",
            "Epoch: 181/250 | Average Epoch Loss: 1.1316794229413345\n",
            "Epoch: 182/250 | Batch: 1/527 | Loss: 1.169567584991455\n",
            "Epoch: 182/250 | Average Epoch Loss: 1.1153739311889634\n",
            "Epoch: 183/250 | Batch: 1/527 | Loss: 0.8049737811088562\n",
            "Epoch: 183/250 | Average Epoch Loss: 1.1366420016116843\n",
            "Epoch: 184/250 | Batch: 1/527 | Loss: 0.7539785504341125\n",
            "Epoch: 184/250 | Average Epoch Loss: 1.1259970400319832\n",
            "Epoch: 185/250 | Batch: 1/527 | Loss: 0.7856953144073486\n",
            "Epoch: 185/250 | Average Epoch Loss: 1.1368931841805041\n",
            "Epoch: 186/250 | Batch: 1/527 | Loss: 1.8679986000061035\n",
            "Epoch: 186/250 | Average Epoch Loss: 1.1117123087171812\n",
            "Epoch: 187/250 | Batch: 1/527 | Loss: 0.7695205807685852\n",
            "Epoch: 187/250 | Average Epoch Loss: 1.115001228774069\n",
            "Epoch: 188/250 | Batch: 1/527 | Loss: 1.176688313484192\n",
            "Epoch: 188/250 | Average Epoch Loss: 1.1234017525723583\n",
            "Epoch: 189/250 | Batch: 1/527 | Loss: 1.1498336791992188\n",
            "Epoch: 189/250 | Average Epoch Loss: 1.145564509297684\n",
            "Epoch: 190/250 | Batch: 1/527 | Loss: 1.149322271347046\n",
            "Epoch: 190/250 | Average Epoch Loss: 1.1193829162975868\n",
            "Epoch: 191/250 | Batch: 1/527 | Loss: 0.7659814953804016\n",
            "Epoch: 191/250 | Average Epoch Loss: 1.1018686145261298\n",
            "Epoch: 192/250 | Batch: 1/527 | Loss: 1.1377283334732056\n",
            "Epoch: 192/250 | Average Epoch Loss: 1.1278542661350186\n",
            "Epoch: 193/250 | Batch: 1/527 | Loss: 0.7588627338409424\n",
            "Epoch: 193/250 | Average Epoch Loss: 1.1072168579816366\n",
            "Epoch: 194/250 | Batch: 1/527 | Loss: 1.1249475479125977\n",
            "Epoch: 194/250 | Average Epoch Loss: 1.1191221094448154\n",
            "Epoch: 195/250 | Batch: 1/527 | Loss: 0.7606515288352966\n",
            "Epoch: 195/250 | Average Epoch Loss: 1.1002688800361171\n",
            "Epoch: 196/250 | Batch: 1/527 | Loss: 1.1015554666519165\n",
            "Epoch: 196/250 | Average Epoch Loss: 1.0960126032865478\n",
            "Epoch: 197/250 | Batch: 1/527 | Loss: 1.8499871492385864\n",
            "Epoch: 197/250 | Average Epoch Loss: 1.1067235411005183\n",
            "Epoch: 198/250 | Batch: 1/527 | Loss: 0.7745470404624939\n",
            "Epoch: 198/250 | Average Epoch Loss: 1.1047450996214343\n",
            "Epoch: 199/250 | Batch: 1/527 | Loss: 1.1260215044021606\n",
            "Epoch: 199/250 | Average Epoch Loss: 1.1034920839928586\n",
            "Epoch: 200/250 | Batch: 1/527 | Loss: 1.4888916015625\n",
            "Epoch: 200/250 | Average Epoch Loss: 1.0959205988236125\n",
            "Epoch: 201/250 | Batch: 1/527 | Loss: 1.1017457246780396\n",
            "Epoch: 201/250 | Average Epoch Loss: 1.108915893357438\n",
            "Epoch: 202/250 | Batch: 1/527 | Loss: 1.4775841236114502\n",
            "Epoch: 202/250 | Average Epoch Loss: 1.0982176310875837\n",
            "Epoch: 203/250 | Batch: 1/527 | Loss: 0.7289850115776062\n",
            "Epoch: 203/250 | Average Epoch Loss: 1.1057351967867683\n",
            "Epoch: 204/250 | Batch: 1/527 | Loss: 1.820261836051941\n",
            "Epoch: 204/250 | Average Epoch Loss: 1.0904102999526137\n",
            "Epoch: 205/250 | Batch: 1/527 | Loss: 1.1480287313461304\n",
            "Epoch: 205/250 | Average Epoch Loss: 1.0936932670097423\n",
            "Epoch: 206/250 | Batch: 1/527 | Loss: 1.1088128089904785\n",
            "Epoch: 206/250 | Average Epoch Loss: 1.0862301973735584\n",
            "Epoch: 207/250 | Batch: 1/527 | Loss: 1.4467089176177979\n",
            "Epoch: 207/250 | Average Epoch Loss: 1.0971147982400102\n",
            "Epoch: 208/250 | Batch: 1/527 | Loss: 1.4886970520019531\n",
            "Epoch: 208/250 | Average Epoch Loss: 1.099043858119161\n",
            "Epoch: 209/250 | Batch: 1/527 | Loss: 0.7587437033653259\n",
            "Epoch: 209/250 | Average Epoch Loss: 1.0843421829267064\n",
            "Epoch: 210/250 | Batch: 1/527 | Loss: 0.7147290706634521\n",
            "Epoch: 210/250 | Average Epoch Loss: 1.0840574465621355\n",
            "Epoch: 211/250 | Batch: 1/527 | Loss: 1.4500302076339722\n",
            "Epoch: 211/250 | Average Epoch Loss: 1.077307237167286\n",
            "Epoch: 212/250 | Batch: 1/527 | Loss: 0.7349380254745483\n",
            "Epoch: 212/250 | Average Epoch Loss: 1.0734317523252352\n",
            "Epoch: 213/250 | Batch: 1/527 | Loss: 0.738894522190094\n",
            "Epoch: 213/250 | Average Epoch Loss: 1.0796800901586687\n",
            "Epoch: 214/250 | Batch: 1/527 | Loss: 1.4624367952346802\n",
            "Epoch: 214/250 | Average Epoch Loss: 1.061750947750497\n",
            "Epoch: 215/250 | Batch: 1/527 | Loss: 0.7327808737754822\n",
            "Epoch: 215/250 | Average Epoch Loss: 1.0701340507058537\n",
            "Epoch: 216/250 | Batch: 1/527 | Loss: 1.4426956176757812\n",
            "Epoch: 216/250 | Average Epoch Loss: 1.0542817346511348\n",
            "Epoch: 217/250 | Batch: 1/527 | Loss: 1.069854974746704\n",
            "Epoch: 217/250 | Average Epoch Loss: 1.0834716128669608\n",
            "Epoch: 218/250 | Batch: 1/527 | Loss: 0.7041046619415283\n",
            "Epoch: 218/250 | Average Epoch Loss: 1.0703651137098642\n",
            "Epoch: 219/250 | Batch: 1/527 | Loss: 0.7252445220947266\n",
            "Epoch: 219/250 | Average Epoch Loss: 1.062936808058614\n",
            "Epoch: 220/250 | Batch: 1/527 | Loss: 0.7162070870399475\n",
            "Epoch: 220/250 | Average Epoch Loss: 1.0692867431966357\n",
            "Epoch: 221/250 | Batch: 1/527 | Loss: 1.4460759162902832\n",
            "Epoch: 221/250 | Average Epoch Loss: 1.0738843258689432\n",
            "Epoch: 222/250 | Batch: 1/527 | Loss: 1.4372614622116089\n",
            "Epoch: 222/250 | Average Epoch Loss: 1.062709361032019\n",
            "Epoch: 223/250 | Batch: 1/527 | Loss: 0.7146587371826172\n",
            "Epoch: 223/250 | Average Epoch Loss: 1.0636876459592208\n",
            "Epoch: 224/250 | Batch: 1/527 | Loss: 0.7391365170478821\n",
            "Epoch: 224/250 | Average Epoch Loss: 1.0620651695262322\n",
            "Epoch: 225/250 | Batch: 1/527 | Loss: 1.4312784671783447\n",
            "Epoch: 225/250 | Average Epoch Loss: 1.0551548535728816\n",
            "Epoch: 226/250 | Batch: 1/527 | Loss: 1.4616135358810425\n",
            "Epoch: 226/250 | Average Epoch Loss: 1.0734293728897195\n",
            "Epoch: 227/250 | Batch: 1/527 | Loss: 1.769824504852295\n",
            "Epoch: 227/250 | Average Epoch Loss: 1.0543450358018025\n",
            "Epoch: 228/250 | Batch: 1/527 | Loss: 1.4276249408721924\n",
            "Epoch: 228/250 | Average Epoch Loss: 1.0387546590881058\n",
            "Epoch: 229/250 | Batch: 1/527 | Loss: 1.437921404838562\n",
            "Epoch: 229/250 | Average Epoch Loss: 1.0188091289838759\n",
            "Epoch: 230/250 | Batch: 1/527 | Loss: 1.0798336267471313\n",
            "Epoch: 230/250 | Average Epoch Loss: 1.0687335536194933\n",
            "Epoch: 231/250 | Batch: 1/527 | Loss: 1.436307430267334\n",
            "Epoch: 231/250 | Average Epoch Loss: 1.0541346575322594\n",
            "Epoch: 232/250 | Batch: 1/527 | Loss: 0.718143880367279\n",
            "Epoch: 232/250 | Average Epoch Loss: 1.0434530580971226\n",
            "Epoch: 233/250 | Batch: 1/527 | Loss: 1.0533024072647095\n",
            "Epoch: 233/250 | Average Epoch Loss: 1.0643135595366895\n",
            "Epoch: 234/250 | Batch: 1/527 | Loss: 0.6955786347389221\n",
            "Epoch: 234/250 | Average Epoch Loss: 1.043358046483722\n",
            "Epoch: 235/250 | Batch: 1/527 | Loss: 1.7779806852340698\n",
            "Epoch: 235/250 | Average Epoch Loss: 1.0559023881094278\n",
            "Epoch: 236/250 | Batch: 1/527 | Loss: 0.6803584694862366\n",
            "Epoch: 236/250 | Average Epoch Loss: 1.031673350868008\n",
            "Epoch: 237/250 | Batch: 1/527 | Loss: 1.0387028455734253\n",
            "Epoch: 237/250 | Average Epoch Loss: 1.0390189025388497\n",
            "Epoch: 238/250 | Batch: 1/527 | Loss: 0.6990100741386414\n",
            "Epoch: 238/250 | Average Epoch Loss: 1.032276674172005\n",
            "Epoch: 239/250 | Batch: 1/527 | Loss: 0.7071042656898499\n",
            "Epoch: 239/250 | Average Epoch Loss: 1.0242518904765598\n",
            "Epoch: 240/250 | Batch: 1/527 | Loss: 1.0668606758117676\n",
            "Epoch: 240/250 | Average Epoch Loss: 1.034695651884097\n",
            "Epoch: 241/250 | Batch: 1/527 | Loss: 1.4100520610809326\n",
            "Epoch: 241/250 | Average Epoch Loss: 1.0518884404334443\n",
            "Epoch: 242/250 | Batch: 1/527 | Loss: 1.3949158191680908\n",
            "Epoch: 242/250 | Average Epoch Loss: 1.0425534891901251\n",
            "Epoch: 243/250 | Batch: 1/527 | Loss: 0.7017945647239685\n",
            "Epoch: 243/250 | Average Epoch Loss: 1.0313609206246697\n",
            "Epoch: 244/250 | Batch: 1/527 | Loss: 1.038441777229309\n",
            "Epoch: 244/250 | Average Epoch Loss: 1.025783276987709\n",
            "Epoch: 245/250 | Batch: 1/527 | Loss: 0.6920114755630493\n",
            "Epoch: 245/250 | Average Epoch Loss: 1.0293525646262196\n",
            "Epoch: 246/250 | Batch: 1/527 | Loss: 0.7090440392494202\n",
            "Epoch: 246/250 | Average Epoch Loss: 1.0303571949195138\n",
            "Epoch: 247/250 | Batch: 1/527 | Loss: 0.7106754183769226\n",
            "Epoch: 247/250 | Average Epoch Loss: 1.0404103105389415\n",
            "Epoch: 248/250 | Batch: 1/527 | Loss: 1.02681303024292\n",
            "Epoch: 248/250 | Average Epoch Loss: 1.016006455249533\n",
            "Epoch: 249/250 | Batch: 1/527 | Loss: 1.0362094640731812\n",
            "Epoch: 249/250 | Average Epoch Loss: 1.0354545152617134\n",
            "Epoch: 250/250 | Batch: 1/527 | Loss: 0.684084951877594\n",
            "Epoch: 250/250 | Average Epoch Loss: 1.0297513330457786\n"
          ]
        }
      ],
      "source": [
        "# train model\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "model_stats = model.train_model(loader=train_loader, optimizer=optimizer, criterion=criterion, epochs=250, print_every=1000)\n",
        "\n",
        "# save model dict\n",
        "torch.save(model_stats, \"drive/MyDrive/without_eos.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Bncn1u9GDP"
      },
      "source": [
        "# Evaluierung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2HcRCpW29GDQ"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "    def __init__(self, model, dataloader, device):\n",
        "        # initiate variables \n",
        "        self.model = model\n",
        "        self.dataloader = dataloader\n",
        "        self.device = device\n",
        "        # self.model.eval()\n",
        "        # assert self.dataloader.batch_size == 1, \"Batch size must be 1 for evaluation.\"\n",
        "    \n",
        "    def evaluate(self):\n",
        "        scores = []\n",
        "\n",
        "        for i, (images, captions, lengths, vectorized_captions) in enumerate(self.dataloader):\n",
        "            # move to device\n",
        "            images = images.to(self.device)\n",
        "            captions = captions.to(self.device)\n",
        "            vectorized_captions = vectorized_captions.to(self.device)\n",
        "            \n",
        "            # forward pass\n",
        "            output = self.model.forward(images)\n",
        "            references = self.model.words[vectorized_captions.cpu()]\n",
        "\n",
        "            for j in range(output.shape[0]):\n",
        "                candidate = self.output_to_sentence(output[j,:])\n",
        "                reference = self.output_to_sentence(references[j,:])\n",
        "                scores.append(self.bleu_score(candidate, reference))\n",
        "            \n",
        "            print(f\"Batch: {i+1} of {len(self.dataloader)}\")\n",
        "\n",
        "        print(f\"Average BLEU score: {np.mean(scores)}\")\n",
        "        return np.mean(scores), scores\n",
        "\n",
        "    @staticmethod\n",
        "    def output_to_sentence(output:list):\n",
        "        '''\n",
        "        Removes Tokens from model output.\n",
        "        '''\n",
        "        output = [token for token in output if token not in [\"<SOS>\", \"<EOS>\", \"<PAD>\"]]\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def bleu_score(reference, candidate):\n",
        "        '''\n",
        "        Calculates the BLEU score for a single reference and candidate. Uses the SmoothingFunction for smoothing when no overlap between certain n-grams is found. \n",
        "\n",
        "        Params:\n",
        "        -------\n",
        "        reference: list of strings - The reference sentence.\n",
        "        candidate: list of strings - The candidate sentence.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        bleu_score: float - The BLEU score.\n",
        "        '''\n",
        "        # calculate the BLEU score\n",
        "        return nltk.translate.bleu_score.sentence_bleu(reference, candidate, smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NttpE3AhHt1M"
      },
      "outputs": [],
      "source": [
        "path = 'drive/MyDrive/without_eos.pt'\n",
        "model_stats = torch.load(path, map_location=device)\n",
        "model = load_captioning_model(model_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U331derr9GDR",
        "outputId": "37e14726-60d8-4025-ecfa-ca7d044e4239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch: 1 of 1055\n",
            "Batch: 2 of 1055\n",
            "Batch: 3 of 1055\n",
            "Batch: 4 of 1055\n",
            "Batch: 5 of 1055\n",
            "Batch: 6 of 1055\n",
            "Batch: 7 of 1055\n",
            "Batch: 8 of 1055\n",
            "Batch: 9 of 1055\n",
            "Batch: 10 of 1055\n",
            "Batch: 11 of 1055\n",
            "Batch: 12 of 1055\n",
            "Batch: 13 of 1055\n",
            "Batch: 14 of 1055\n",
            "Batch: 15 of 1055\n",
            "Batch: 16 of 1055\n",
            "Batch: 17 of 1055\n",
            "Batch: 18 of 1055\n",
            "Batch: 19 of 1055\n",
            "Batch: 20 of 1055\n",
            "Batch: 21 of 1055\n",
            "Batch: 22 of 1055\n",
            "Batch: 23 of 1055\n",
            "Batch: 24 of 1055\n",
            "Batch: 25 of 1055\n",
            "Batch: 26 of 1055\n",
            "Batch: 27 of 1055\n",
            "Batch: 28 of 1055\n",
            "Batch: 29 of 1055\n",
            "Batch: 30 of 1055\n",
            "Batch: 31 of 1055\n",
            "Batch: 32 of 1055\n",
            "Batch: 33 of 1055\n",
            "Batch: 34 of 1055\n",
            "Batch: 35 of 1055\n",
            "Batch: 36 of 1055\n",
            "Batch: 37 of 1055\n",
            "Batch: 38 of 1055\n",
            "Batch: 39 of 1055\n",
            "Batch: 40 of 1055\n",
            "Batch: 41 of 1055\n",
            "Batch: 42 of 1055\n",
            "Batch: 43 of 1055\n",
            "Batch: 44 of 1055\n",
            "Batch: 45 of 1055\n",
            "Batch: 46 of 1055\n",
            "Batch: 47 of 1055\n",
            "Batch: 48 of 1055\n",
            "Batch: 49 of 1055\n",
            "Batch: 50 of 1055\n",
            "Batch: 51 of 1055\n",
            "Batch: 52 of 1055\n",
            "Batch: 53 of 1055\n",
            "Batch: 54 of 1055\n",
            "Batch: 55 of 1055\n",
            "Batch: 56 of 1055\n",
            "Batch: 57 of 1055\n",
            "Batch: 58 of 1055\n",
            "Batch: 59 of 1055\n",
            "Batch: 60 of 1055\n",
            "Batch: 61 of 1055\n",
            "Batch: 62 of 1055\n",
            "Batch: 63 of 1055\n",
            "Batch: 64 of 1055\n",
            "Batch: 65 of 1055\n",
            "Batch: 66 of 1055\n",
            "Batch: 67 of 1055\n",
            "Batch: 68 of 1055\n",
            "Batch: 69 of 1055\n",
            "Batch: 70 of 1055\n",
            "Batch: 71 of 1055\n",
            "Batch: 72 of 1055\n",
            "Batch: 73 of 1055\n",
            "Batch: 74 of 1055\n",
            "Batch: 75 of 1055\n",
            "Batch: 76 of 1055\n",
            "Batch: 77 of 1055\n",
            "Batch: 78 of 1055\n",
            "Batch: 79 of 1055\n",
            "Batch: 80 of 1055\n",
            "Batch: 81 of 1055\n",
            "Batch: 82 of 1055\n",
            "Batch: 83 of 1055\n",
            "Batch: 84 of 1055\n",
            "Batch: 85 of 1055\n",
            "Batch: 86 of 1055\n",
            "Batch: 87 of 1055\n",
            "Batch: 88 of 1055\n",
            "Batch: 89 of 1055\n",
            "Batch: 90 of 1055\n",
            "Batch: 91 of 1055\n",
            "Batch: 92 of 1055\n",
            "Batch: 93 of 1055\n",
            "Batch: 94 of 1055\n",
            "Batch: 95 of 1055\n",
            "Batch: 96 of 1055\n",
            "Batch: 97 of 1055\n",
            "Batch: 98 of 1055\n",
            "Batch: 99 of 1055\n",
            "Batch: 100 of 1055\n",
            "Batch: 101 of 1055\n",
            "Batch: 102 of 1055\n",
            "Batch: 103 of 1055\n",
            "Batch: 104 of 1055\n",
            "Batch: 105 of 1055\n",
            "Batch: 106 of 1055\n",
            "Batch: 107 of 1055\n",
            "Batch: 108 of 1055\n",
            "Batch: 109 of 1055\n",
            "Batch: 110 of 1055\n",
            "Batch: 111 of 1055\n",
            "Batch: 112 of 1055\n",
            "Batch: 113 of 1055\n",
            "Batch: 114 of 1055\n",
            "Batch: 115 of 1055\n",
            "Batch: 116 of 1055\n",
            "Batch: 117 of 1055\n",
            "Batch: 118 of 1055\n",
            "Batch: 119 of 1055\n",
            "Batch: 120 of 1055\n",
            "Batch: 121 of 1055\n",
            "Batch: 122 of 1055\n",
            "Batch: 123 of 1055\n",
            "Batch: 124 of 1055\n",
            "Batch: 125 of 1055\n",
            "Batch: 126 of 1055\n",
            "Batch: 127 of 1055\n",
            "Batch: 128 of 1055\n",
            "Batch: 129 of 1055\n",
            "Batch: 130 of 1055\n",
            "Batch: 131 of 1055\n",
            "Batch: 132 of 1055\n",
            "Batch: 133 of 1055\n",
            "Batch: 134 of 1055\n",
            "Batch: 135 of 1055\n",
            "Batch: 136 of 1055\n",
            "Batch: 137 of 1055\n",
            "Batch: 138 of 1055\n",
            "Batch: 139 of 1055\n",
            "Batch: 140 of 1055\n",
            "Batch: 141 of 1055\n",
            "Batch: 142 of 1055\n",
            "Batch: 143 of 1055\n",
            "Batch: 144 of 1055\n",
            "Batch: 145 of 1055\n",
            "Batch: 146 of 1055\n",
            "Batch: 147 of 1055\n",
            "Batch: 148 of 1055\n",
            "Batch: 149 of 1055\n",
            "Batch: 150 of 1055\n",
            "Batch: 151 of 1055\n",
            "Batch: 152 of 1055\n",
            "Batch: 153 of 1055\n",
            "Batch: 154 of 1055\n",
            "Batch: 155 of 1055\n",
            "Batch: 156 of 1055\n",
            "Batch: 157 of 1055\n",
            "Batch: 158 of 1055\n",
            "Batch: 159 of 1055\n",
            "Batch: 160 of 1055\n",
            "Batch: 161 of 1055\n",
            "Batch: 162 of 1055\n",
            "Batch: 163 of 1055\n",
            "Batch: 164 of 1055\n",
            "Batch: 165 of 1055\n",
            "Batch: 166 of 1055\n",
            "Batch: 167 of 1055\n",
            "Batch: 168 of 1055\n",
            "Batch: 169 of 1055\n",
            "Batch: 170 of 1055\n",
            "Batch: 171 of 1055\n",
            "Batch: 172 of 1055\n",
            "Batch: 173 of 1055\n",
            "Batch: 174 of 1055\n",
            "Batch: 175 of 1055\n",
            "Batch: 176 of 1055\n",
            "Batch: 177 of 1055\n",
            "Batch: 178 of 1055\n",
            "Batch: 179 of 1055\n",
            "Batch: 180 of 1055\n",
            "Batch: 181 of 1055\n",
            "Batch: 182 of 1055\n",
            "Batch: 183 of 1055\n",
            "Batch: 184 of 1055\n",
            "Batch: 185 of 1055\n",
            "Batch: 186 of 1055\n",
            "Batch: 187 of 1055\n",
            "Batch: 188 of 1055\n",
            "Batch: 189 of 1055\n",
            "Batch: 190 of 1055\n",
            "Batch: 191 of 1055\n",
            "Batch: 192 of 1055\n",
            "Batch: 193 of 1055\n",
            "Batch: 194 of 1055\n",
            "Batch: 195 of 1055\n",
            "Batch: 196 of 1055\n",
            "Batch: 197 of 1055\n",
            "Batch: 198 of 1055\n",
            "Batch: 199 of 1055\n",
            "Batch: 200 of 1055\n",
            "Batch: 201 of 1055\n",
            "Batch: 202 of 1055\n",
            "Batch: 203 of 1055\n",
            "Batch: 204 of 1055\n",
            "Batch: 205 of 1055\n",
            "Batch: 206 of 1055\n",
            "Batch: 207 of 1055\n",
            "Batch: 208 of 1055\n",
            "Batch: 209 of 1055\n",
            "Batch: 210 of 1055\n",
            "Batch: 211 of 1055\n",
            "Batch: 212 of 1055\n",
            "Batch: 213 of 1055\n",
            "Batch: 214 of 1055\n",
            "Batch: 215 of 1055\n",
            "Batch: 216 of 1055\n",
            "Batch: 217 of 1055\n",
            "Batch: 218 of 1055\n",
            "Batch: 219 of 1055\n",
            "Batch: 220 of 1055\n",
            "Batch: 221 of 1055\n",
            "Batch: 222 of 1055\n",
            "Batch: 223 of 1055\n",
            "Batch: 224 of 1055\n",
            "Batch: 225 of 1055\n",
            "Batch: 226 of 1055\n",
            "Batch: 227 of 1055\n",
            "Batch: 228 of 1055\n",
            "Batch: 229 of 1055\n",
            "Batch: 230 of 1055\n",
            "Batch: 231 of 1055\n",
            "Batch: 232 of 1055\n",
            "Batch: 233 of 1055\n",
            "Batch: 234 of 1055\n",
            "Batch: 235 of 1055\n",
            "Batch: 236 of 1055\n",
            "Batch: 237 of 1055\n",
            "Batch: 238 of 1055\n",
            "Batch: 239 of 1055\n",
            "Batch: 240 of 1055\n",
            "Batch: 241 of 1055\n",
            "Batch: 242 of 1055\n",
            "Batch: 243 of 1055\n",
            "Batch: 244 of 1055\n",
            "Batch: 245 of 1055\n",
            "Batch: 246 of 1055\n",
            "Batch: 247 of 1055\n",
            "Batch: 248 of 1055\n",
            "Batch: 249 of 1055\n",
            "Batch: 250 of 1055\n",
            "Batch: 251 of 1055\n",
            "Batch: 252 of 1055\n",
            "Batch: 253 of 1055\n",
            "Batch: 254 of 1055\n",
            "Batch: 255 of 1055\n",
            "Batch: 256 of 1055\n",
            "Batch: 257 of 1055\n",
            "Batch: 258 of 1055\n",
            "Batch: 259 of 1055\n",
            "Batch: 260 of 1055\n",
            "Batch: 261 of 1055\n",
            "Batch: 262 of 1055\n",
            "Batch: 263 of 1055\n",
            "Batch: 264 of 1055\n",
            "Batch: 265 of 1055\n",
            "Batch: 266 of 1055\n",
            "Batch: 267 of 1055\n",
            "Batch: 268 of 1055\n",
            "Batch: 269 of 1055\n",
            "Batch: 270 of 1055\n",
            "Batch: 271 of 1055\n",
            "Batch: 272 of 1055\n",
            "Batch: 273 of 1055\n",
            "Batch: 274 of 1055\n",
            "Batch: 275 of 1055\n",
            "Batch: 276 of 1055\n",
            "Batch: 277 of 1055\n",
            "Batch: 278 of 1055\n",
            "Batch: 279 of 1055\n",
            "Batch: 280 of 1055\n",
            "Batch: 281 of 1055\n",
            "Batch: 282 of 1055\n",
            "Batch: 283 of 1055\n",
            "Batch: 284 of 1055\n",
            "Batch: 285 of 1055\n",
            "Batch: 286 of 1055\n",
            "Batch: 287 of 1055\n",
            "Batch: 288 of 1055\n",
            "Batch: 289 of 1055\n",
            "Batch: 290 of 1055\n",
            "Batch: 291 of 1055\n",
            "Batch: 292 of 1055\n",
            "Batch: 293 of 1055\n",
            "Batch: 294 of 1055\n",
            "Batch: 295 of 1055\n",
            "Batch: 296 of 1055\n",
            "Batch: 297 of 1055\n",
            "Batch: 298 of 1055\n",
            "Batch: 299 of 1055\n",
            "Batch: 300 of 1055\n",
            "Batch: 301 of 1055\n",
            "Batch: 302 of 1055\n",
            "Batch: 303 of 1055\n",
            "Batch: 304 of 1055\n",
            "Batch: 305 of 1055\n",
            "Batch: 306 of 1055\n",
            "Batch: 307 of 1055\n",
            "Batch: 308 of 1055\n",
            "Batch: 309 of 1055\n",
            "Batch: 310 of 1055\n",
            "Batch: 311 of 1055\n",
            "Batch: 312 of 1055\n",
            "Batch: 313 of 1055\n",
            "Batch: 314 of 1055\n",
            "Batch: 315 of 1055\n",
            "Batch: 316 of 1055\n",
            "Batch: 317 of 1055\n",
            "Batch: 318 of 1055\n",
            "Batch: 319 of 1055\n",
            "Batch: 320 of 1055\n",
            "Batch: 321 of 1055\n",
            "Batch: 322 of 1055\n",
            "Batch: 323 of 1055\n",
            "Batch: 324 of 1055\n",
            "Batch: 325 of 1055\n",
            "Batch: 326 of 1055\n",
            "Batch: 327 of 1055\n",
            "Batch: 328 of 1055\n",
            "Batch: 329 of 1055\n",
            "Batch: 330 of 1055\n",
            "Batch: 331 of 1055\n",
            "Batch: 332 of 1055\n",
            "Batch: 333 of 1055\n",
            "Batch: 334 of 1055\n",
            "Batch: 335 of 1055\n",
            "Batch: 336 of 1055\n",
            "Batch: 337 of 1055\n",
            "Batch: 338 of 1055\n",
            "Batch: 339 of 1055\n",
            "Batch: 340 of 1055\n",
            "Batch: 341 of 1055\n",
            "Batch: 342 of 1055\n",
            "Batch: 343 of 1055\n",
            "Batch: 344 of 1055\n",
            "Batch: 345 of 1055\n",
            "Batch: 346 of 1055\n",
            "Batch: 347 of 1055\n",
            "Batch: 348 of 1055\n",
            "Batch: 349 of 1055\n",
            "Batch: 350 of 1055\n",
            "Batch: 351 of 1055\n",
            "Batch: 352 of 1055\n",
            "Batch: 353 of 1055\n",
            "Batch: 354 of 1055\n",
            "Batch: 355 of 1055\n",
            "Batch: 356 of 1055\n",
            "Batch: 357 of 1055\n",
            "Batch: 358 of 1055\n",
            "Batch: 359 of 1055\n",
            "Batch: 360 of 1055\n",
            "Batch: 361 of 1055\n",
            "Batch: 362 of 1055\n",
            "Batch: 363 of 1055\n",
            "Batch: 364 of 1055\n",
            "Batch: 365 of 1055\n",
            "Batch: 366 of 1055\n",
            "Batch: 367 of 1055\n",
            "Batch: 368 of 1055\n",
            "Batch: 369 of 1055\n",
            "Batch: 370 of 1055\n",
            "Batch: 371 of 1055\n",
            "Batch: 372 of 1055\n",
            "Batch: 373 of 1055\n",
            "Batch: 374 of 1055\n",
            "Batch: 375 of 1055\n",
            "Batch: 376 of 1055\n",
            "Batch: 377 of 1055\n",
            "Batch: 378 of 1055\n",
            "Batch: 379 of 1055\n",
            "Batch: 380 of 1055\n",
            "Batch: 381 of 1055\n",
            "Batch: 382 of 1055\n",
            "Batch: 383 of 1055\n",
            "Batch: 384 of 1055\n",
            "Batch: 385 of 1055\n",
            "Batch: 386 of 1055\n",
            "Batch: 387 of 1055\n",
            "Batch: 388 of 1055\n",
            "Batch: 389 of 1055\n",
            "Batch: 390 of 1055\n",
            "Batch: 391 of 1055\n",
            "Batch: 392 of 1055\n",
            "Batch: 393 of 1055\n",
            "Batch: 394 of 1055\n",
            "Batch: 395 of 1055\n",
            "Batch: 396 of 1055\n",
            "Batch: 397 of 1055\n",
            "Batch: 398 of 1055\n",
            "Batch: 399 of 1055\n",
            "Batch: 400 of 1055\n",
            "Batch: 401 of 1055\n",
            "Batch: 402 of 1055\n",
            "Batch: 403 of 1055\n",
            "Batch: 404 of 1055\n",
            "Batch: 405 of 1055\n",
            "Batch: 406 of 1055\n",
            "Batch: 407 of 1055\n",
            "Batch: 408 of 1055\n",
            "Batch: 409 of 1055\n",
            "Batch: 410 of 1055\n",
            "Batch: 411 of 1055\n",
            "Batch: 412 of 1055\n",
            "Batch: 413 of 1055\n",
            "Batch: 414 of 1055\n",
            "Batch: 415 of 1055\n",
            "Batch: 416 of 1055\n",
            "Batch: 417 of 1055\n",
            "Batch: 418 of 1055\n",
            "Batch: 419 of 1055\n",
            "Batch: 420 of 1055\n",
            "Batch: 421 of 1055\n",
            "Batch: 422 of 1055\n",
            "Batch: 423 of 1055\n",
            "Batch: 424 of 1055\n",
            "Batch: 425 of 1055\n",
            "Batch: 426 of 1055\n",
            "Batch: 427 of 1055\n",
            "Batch: 428 of 1055\n",
            "Batch: 429 of 1055\n",
            "Batch: 430 of 1055\n",
            "Batch: 431 of 1055\n",
            "Batch: 432 of 1055\n",
            "Batch: 433 of 1055\n",
            "Batch: 434 of 1055\n",
            "Batch: 435 of 1055\n",
            "Batch: 436 of 1055\n",
            "Batch: 437 of 1055\n",
            "Batch: 438 of 1055\n",
            "Batch: 439 of 1055\n",
            "Batch: 440 of 1055\n",
            "Batch: 441 of 1055\n",
            "Batch: 442 of 1055\n",
            "Batch: 443 of 1055\n",
            "Batch: 444 of 1055\n",
            "Batch: 445 of 1055\n",
            "Batch: 446 of 1055\n",
            "Batch: 447 of 1055\n",
            "Batch: 448 of 1055\n",
            "Batch: 449 of 1055\n",
            "Batch: 450 of 1055\n",
            "Batch: 451 of 1055\n",
            "Batch: 452 of 1055\n",
            "Batch: 453 of 1055\n",
            "Batch: 454 of 1055\n",
            "Batch: 455 of 1055\n",
            "Batch: 456 of 1055\n",
            "Batch: 457 of 1055\n",
            "Batch: 458 of 1055\n",
            "Batch: 459 of 1055\n",
            "Batch: 460 of 1055\n",
            "Batch: 461 of 1055\n",
            "Batch: 462 of 1055\n",
            "Batch: 463 of 1055\n",
            "Batch: 464 of 1055\n",
            "Batch: 465 of 1055\n",
            "Batch: 466 of 1055\n",
            "Batch: 467 of 1055\n",
            "Batch: 468 of 1055\n",
            "Batch: 469 of 1055\n",
            "Batch: 470 of 1055\n",
            "Batch: 471 of 1055\n",
            "Batch: 472 of 1055\n",
            "Batch: 473 of 1055\n",
            "Batch: 474 of 1055\n",
            "Batch: 475 of 1055\n",
            "Batch: 476 of 1055\n",
            "Batch: 477 of 1055\n",
            "Batch: 478 of 1055\n",
            "Batch: 479 of 1055\n",
            "Batch: 480 of 1055\n",
            "Batch: 481 of 1055\n",
            "Batch: 482 of 1055\n",
            "Batch: 483 of 1055\n",
            "Batch: 484 of 1055\n",
            "Batch: 485 of 1055\n",
            "Batch: 486 of 1055\n",
            "Batch: 487 of 1055\n",
            "Batch: 488 of 1055\n",
            "Batch: 489 of 1055\n",
            "Batch: 490 of 1055\n",
            "Batch: 491 of 1055\n",
            "Batch: 492 of 1055\n",
            "Batch: 493 of 1055\n",
            "Batch: 494 of 1055\n",
            "Batch: 495 of 1055\n",
            "Batch: 496 of 1055\n",
            "Batch: 497 of 1055\n",
            "Batch: 498 of 1055\n",
            "Batch: 499 of 1055\n",
            "Batch: 500 of 1055\n",
            "Batch: 501 of 1055\n",
            "Batch: 502 of 1055\n",
            "Batch: 503 of 1055\n",
            "Batch: 504 of 1055\n",
            "Batch: 505 of 1055\n",
            "Batch: 506 of 1055\n",
            "Batch: 507 of 1055\n",
            "Batch: 508 of 1055\n",
            "Batch: 509 of 1055\n",
            "Batch: 510 of 1055\n",
            "Batch: 511 of 1055\n",
            "Batch: 512 of 1055\n",
            "Batch: 513 of 1055\n",
            "Batch: 514 of 1055\n",
            "Batch: 515 of 1055\n",
            "Batch: 516 of 1055\n",
            "Batch: 517 of 1055\n",
            "Batch: 518 of 1055\n",
            "Batch: 519 of 1055\n",
            "Batch: 520 of 1055\n",
            "Batch: 521 of 1055\n",
            "Batch: 522 of 1055\n",
            "Batch: 523 of 1055\n",
            "Batch: 524 of 1055\n",
            "Batch: 525 of 1055\n",
            "Batch: 526 of 1055\n",
            "Batch: 527 of 1055\n",
            "Batch: 528 of 1055\n",
            "Batch: 529 of 1055\n",
            "Batch: 530 of 1055\n",
            "Batch: 531 of 1055\n",
            "Batch: 532 of 1055\n",
            "Batch: 533 of 1055\n",
            "Batch: 534 of 1055\n",
            "Batch: 535 of 1055\n",
            "Batch: 536 of 1055\n",
            "Batch: 537 of 1055\n",
            "Batch: 538 of 1055\n",
            "Batch: 539 of 1055\n",
            "Batch: 540 of 1055\n",
            "Batch: 541 of 1055\n",
            "Batch: 542 of 1055\n",
            "Batch: 543 of 1055\n",
            "Batch: 544 of 1055\n",
            "Batch: 545 of 1055\n",
            "Batch: 546 of 1055\n",
            "Batch: 547 of 1055\n",
            "Batch: 548 of 1055\n",
            "Batch: 549 of 1055\n",
            "Batch: 550 of 1055\n",
            "Batch: 551 of 1055\n",
            "Batch: 552 of 1055\n",
            "Batch: 553 of 1055\n",
            "Batch: 554 of 1055\n",
            "Batch: 555 of 1055\n",
            "Batch: 556 of 1055\n",
            "Batch: 557 of 1055\n",
            "Batch: 558 of 1055\n",
            "Batch: 559 of 1055\n",
            "Batch: 560 of 1055\n",
            "Batch: 561 of 1055\n",
            "Batch: 562 of 1055\n",
            "Batch: 563 of 1055\n",
            "Batch: 564 of 1055\n",
            "Batch: 565 of 1055\n",
            "Batch: 566 of 1055\n",
            "Batch: 567 of 1055\n",
            "Batch: 568 of 1055\n",
            "Batch: 569 of 1055\n",
            "Batch: 570 of 1055\n",
            "Batch: 571 of 1055\n",
            "Batch: 572 of 1055\n",
            "Batch: 573 of 1055\n",
            "Batch: 574 of 1055\n",
            "Batch: 575 of 1055\n",
            "Batch: 576 of 1055\n",
            "Batch: 577 of 1055\n",
            "Batch: 578 of 1055\n",
            "Batch: 579 of 1055\n",
            "Batch: 580 of 1055\n",
            "Batch: 581 of 1055\n",
            "Batch: 582 of 1055\n",
            "Batch: 583 of 1055\n",
            "Batch: 584 of 1055\n",
            "Batch: 585 of 1055\n",
            "Batch: 586 of 1055\n",
            "Batch: 587 of 1055\n",
            "Batch: 588 of 1055\n",
            "Batch: 589 of 1055\n",
            "Batch: 590 of 1055\n",
            "Batch: 591 of 1055\n",
            "Batch: 592 of 1055\n",
            "Batch: 593 of 1055\n",
            "Batch: 594 of 1055\n",
            "Batch: 595 of 1055\n",
            "Batch: 596 of 1055\n",
            "Batch: 597 of 1055\n",
            "Batch: 598 of 1055\n",
            "Batch: 599 of 1055\n",
            "Batch: 600 of 1055\n",
            "Batch: 601 of 1055\n",
            "Batch: 602 of 1055\n",
            "Batch: 603 of 1055\n",
            "Batch: 604 of 1055\n",
            "Batch: 605 of 1055\n",
            "Batch: 606 of 1055\n",
            "Batch: 607 of 1055\n",
            "Batch: 608 of 1055\n",
            "Batch: 609 of 1055\n",
            "Batch: 610 of 1055\n",
            "Batch: 611 of 1055\n",
            "Batch: 612 of 1055\n",
            "Batch: 613 of 1055\n",
            "Batch: 614 of 1055\n",
            "Batch: 615 of 1055\n",
            "Batch: 616 of 1055\n",
            "Batch: 617 of 1055\n",
            "Batch: 618 of 1055\n",
            "Batch: 619 of 1055\n",
            "Batch: 620 of 1055\n",
            "Batch: 621 of 1055\n",
            "Batch: 622 of 1055\n",
            "Batch: 623 of 1055\n",
            "Batch: 624 of 1055\n",
            "Batch: 625 of 1055\n",
            "Batch: 626 of 1055\n",
            "Batch: 627 of 1055\n",
            "Batch: 628 of 1055\n",
            "Batch: 629 of 1055\n",
            "Batch: 630 of 1055\n",
            "Batch: 631 of 1055\n",
            "Batch: 632 of 1055\n",
            "Batch: 633 of 1055\n",
            "Batch: 634 of 1055\n",
            "Batch: 635 of 1055\n",
            "Batch: 636 of 1055\n",
            "Batch: 637 of 1055\n",
            "Batch: 638 of 1055\n",
            "Batch: 639 of 1055\n",
            "Batch: 640 of 1055\n",
            "Batch: 641 of 1055\n",
            "Batch: 642 of 1055\n",
            "Batch: 643 of 1055\n",
            "Batch: 644 of 1055\n",
            "Batch: 645 of 1055\n",
            "Batch: 646 of 1055\n",
            "Batch: 647 of 1055\n",
            "Batch: 648 of 1055\n",
            "Batch: 649 of 1055\n",
            "Batch: 650 of 1055\n",
            "Batch: 651 of 1055\n",
            "Batch: 652 of 1055\n",
            "Batch: 653 of 1055\n",
            "Batch: 654 of 1055\n",
            "Batch: 655 of 1055\n",
            "Batch: 656 of 1055\n",
            "Batch: 657 of 1055\n",
            "Batch: 658 of 1055\n",
            "Batch: 659 of 1055\n",
            "Batch: 660 of 1055\n",
            "Batch: 661 of 1055\n",
            "Batch: 662 of 1055\n",
            "Batch: 663 of 1055\n",
            "Batch: 664 of 1055\n",
            "Batch: 665 of 1055\n",
            "Batch: 666 of 1055\n",
            "Batch: 667 of 1055\n",
            "Batch: 668 of 1055\n",
            "Batch: 669 of 1055\n",
            "Batch: 670 of 1055\n",
            "Batch: 671 of 1055\n",
            "Batch: 672 of 1055\n",
            "Batch: 673 of 1055\n",
            "Batch: 674 of 1055\n",
            "Batch: 675 of 1055\n",
            "Batch: 676 of 1055\n",
            "Batch: 677 of 1055\n",
            "Batch: 678 of 1055\n",
            "Batch: 679 of 1055\n",
            "Batch: 680 of 1055\n",
            "Batch: 681 of 1055\n",
            "Batch: 682 of 1055\n",
            "Batch: 683 of 1055\n",
            "Batch: 684 of 1055\n",
            "Batch: 685 of 1055\n",
            "Batch: 686 of 1055\n",
            "Batch: 687 of 1055\n",
            "Batch: 688 of 1055\n",
            "Batch: 689 of 1055\n",
            "Batch: 690 of 1055\n",
            "Batch: 691 of 1055\n",
            "Batch: 692 of 1055\n",
            "Batch: 693 of 1055\n",
            "Batch: 694 of 1055\n",
            "Batch: 695 of 1055\n",
            "Batch: 696 of 1055\n",
            "Batch: 697 of 1055\n",
            "Batch: 698 of 1055\n",
            "Batch: 699 of 1055\n",
            "Batch: 700 of 1055\n",
            "Batch: 701 of 1055\n",
            "Batch: 702 of 1055\n",
            "Batch: 703 of 1055\n",
            "Batch: 704 of 1055\n",
            "Batch: 705 of 1055\n",
            "Batch: 706 of 1055\n",
            "Batch: 707 of 1055\n",
            "Batch: 708 of 1055\n",
            "Batch: 709 of 1055\n",
            "Batch: 710 of 1055\n",
            "Batch: 711 of 1055\n",
            "Batch: 712 of 1055\n",
            "Batch: 713 of 1055\n",
            "Batch: 714 of 1055\n",
            "Batch: 715 of 1055\n",
            "Batch: 716 of 1055\n",
            "Batch: 717 of 1055\n",
            "Batch: 718 of 1055\n",
            "Batch: 719 of 1055\n",
            "Batch: 720 of 1055\n",
            "Batch: 721 of 1055\n",
            "Batch: 722 of 1055\n",
            "Batch: 723 of 1055\n",
            "Batch: 724 of 1055\n",
            "Batch: 725 of 1055\n",
            "Batch: 726 of 1055\n",
            "Batch: 727 of 1055\n",
            "Batch: 728 of 1055\n",
            "Batch: 729 of 1055\n",
            "Batch: 730 of 1055\n",
            "Batch: 731 of 1055\n",
            "Batch: 732 of 1055\n",
            "Batch: 733 of 1055\n",
            "Batch: 734 of 1055\n",
            "Batch: 735 of 1055\n",
            "Batch: 736 of 1055\n",
            "Batch: 737 of 1055\n",
            "Batch: 738 of 1055\n",
            "Batch: 739 of 1055\n",
            "Batch: 740 of 1055\n",
            "Batch: 741 of 1055\n",
            "Batch: 742 of 1055\n",
            "Batch: 743 of 1055\n",
            "Batch: 744 of 1055\n",
            "Batch: 745 of 1055\n",
            "Batch: 746 of 1055\n",
            "Batch: 747 of 1055\n",
            "Batch: 748 of 1055\n",
            "Batch: 749 of 1055\n",
            "Batch: 750 of 1055\n",
            "Batch: 751 of 1055\n",
            "Batch: 752 of 1055\n",
            "Batch: 753 of 1055\n",
            "Batch: 754 of 1055\n",
            "Batch: 755 of 1055\n",
            "Batch: 756 of 1055\n",
            "Batch: 757 of 1055\n",
            "Batch: 758 of 1055\n",
            "Batch: 759 of 1055\n",
            "Batch: 760 of 1055\n",
            "Batch: 761 of 1055\n",
            "Batch: 762 of 1055\n",
            "Batch: 763 of 1055\n",
            "Batch: 764 of 1055\n",
            "Batch: 765 of 1055\n",
            "Batch: 766 of 1055\n",
            "Batch: 767 of 1055\n",
            "Batch: 768 of 1055\n",
            "Batch: 769 of 1055\n",
            "Batch: 770 of 1055\n",
            "Batch: 771 of 1055\n",
            "Batch: 772 of 1055\n",
            "Batch: 773 of 1055\n",
            "Batch: 774 of 1055\n",
            "Batch: 775 of 1055\n",
            "Batch: 776 of 1055\n",
            "Batch: 777 of 1055\n",
            "Batch: 778 of 1055\n",
            "Batch: 779 of 1055\n",
            "Batch: 780 of 1055\n",
            "Batch: 781 of 1055\n",
            "Batch: 782 of 1055\n",
            "Batch: 783 of 1055\n",
            "Batch: 784 of 1055\n",
            "Batch: 785 of 1055\n",
            "Batch: 786 of 1055\n",
            "Batch: 787 of 1055\n",
            "Batch: 788 of 1055\n",
            "Batch: 789 of 1055\n",
            "Batch: 790 of 1055\n",
            "Batch: 791 of 1055\n",
            "Batch: 792 of 1055\n",
            "Batch: 793 of 1055\n",
            "Batch: 794 of 1055\n",
            "Batch: 795 of 1055\n",
            "Batch: 796 of 1055\n",
            "Batch: 797 of 1055\n",
            "Batch: 798 of 1055\n",
            "Batch: 799 of 1055\n",
            "Batch: 800 of 1055\n",
            "Batch: 801 of 1055\n",
            "Batch: 802 of 1055\n",
            "Batch: 803 of 1055\n",
            "Batch: 804 of 1055\n",
            "Batch: 805 of 1055\n",
            "Batch: 806 of 1055\n",
            "Batch: 807 of 1055\n",
            "Batch: 808 of 1055\n",
            "Batch: 809 of 1055\n",
            "Batch: 810 of 1055\n",
            "Batch: 811 of 1055\n",
            "Batch: 812 of 1055\n",
            "Batch: 813 of 1055\n",
            "Batch: 814 of 1055\n",
            "Batch: 815 of 1055\n",
            "Batch: 816 of 1055\n",
            "Batch: 817 of 1055\n",
            "Batch: 818 of 1055\n",
            "Batch: 819 of 1055\n",
            "Batch: 820 of 1055\n",
            "Batch: 821 of 1055\n",
            "Batch: 822 of 1055\n",
            "Batch: 823 of 1055\n",
            "Batch: 824 of 1055\n",
            "Batch: 825 of 1055\n",
            "Batch: 826 of 1055\n",
            "Batch: 827 of 1055\n",
            "Batch: 828 of 1055\n",
            "Batch: 829 of 1055\n",
            "Batch: 830 of 1055\n",
            "Batch: 831 of 1055\n",
            "Batch: 832 of 1055\n",
            "Batch: 833 of 1055\n",
            "Batch: 834 of 1055\n",
            "Batch: 835 of 1055\n",
            "Batch: 836 of 1055\n",
            "Batch: 837 of 1055\n",
            "Batch: 838 of 1055\n",
            "Batch: 839 of 1055\n",
            "Batch: 840 of 1055\n",
            "Batch: 841 of 1055\n",
            "Batch: 842 of 1055\n",
            "Batch: 843 of 1055\n",
            "Batch: 844 of 1055\n",
            "Batch: 845 of 1055\n",
            "Batch: 846 of 1055\n",
            "Batch: 847 of 1055\n",
            "Batch: 848 of 1055\n",
            "Batch: 849 of 1055\n",
            "Batch: 850 of 1055\n",
            "Batch: 851 of 1055\n",
            "Batch: 852 of 1055\n",
            "Batch: 853 of 1055\n",
            "Batch: 854 of 1055\n",
            "Batch: 855 of 1055\n",
            "Batch: 856 of 1055\n",
            "Batch: 857 of 1055\n",
            "Batch: 858 of 1055\n",
            "Batch: 859 of 1055\n",
            "Batch: 860 of 1055\n",
            "Batch: 861 of 1055\n",
            "Batch: 862 of 1055\n",
            "Batch: 863 of 1055\n",
            "Batch: 864 of 1055\n",
            "Batch: 865 of 1055\n",
            "Batch: 866 of 1055\n",
            "Batch: 867 of 1055\n",
            "Batch: 868 of 1055\n",
            "Batch: 869 of 1055\n",
            "Batch: 870 of 1055\n",
            "Batch: 871 of 1055\n",
            "Batch: 872 of 1055\n",
            "Batch: 873 of 1055\n",
            "Batch: 874 of 1055\n",
            "Batch: 875 of 1055\n",
            "Batch: 876 of 1055\n",
            "Batch: 877 of 1055\n",
            "Batch: 878 of 1055\n",
            "Batch: 879 of 1055\n",
            "Batch: 880 of 1055\n",
            "Batch: 881 of 1055\n",
            "Batch: 882 of 1055\n",
            "Batch: 883 of 1055\n",
            "Batch: 884 of 1055\n",
            "Batch: 885 of 1055\n",
            "Batch: 886 of 1055\n",
            "Batch: 887 of 1055\n",
            "Batch: 888 of 1055\n",
            "Batch: 889 of 1055\n",
            "Batch: 890 of 1055\n",
            "Batch: 891 of 1055\n",
            "Batch: 892 of 1055\n",
            "Batch: 893 of 1055\n",
            "Batch: 894 of 1055\n",
            "Batch: 895 of 1055\n",
            "Batch: 896 of 1055\n",
            "Batch: 897 of 1055\n",
            "Batch: 898 of 1055\n",
            "Batch: 899 of 1055\n",
            "Batch: 900 of 1055\n",
            "Batch: 901 of 1055\n",
            "Batch: 902 of 1055\n",
            "Batch: 903 of 1055\n",
            "Batch: 904 of 1055\n",
            "Batch: 905 of 1055\n",
            "Batch: 906 of 1055\n",
            "Batch: 907 of 1055\n",
            "Batch: 908 of 1055\n",
            "Batch: 909 of 1055\n",
            "Batch: 910 of 1055\n",
            "Batch: 911 of 1055\n",
            "Batch: 912 of 1055\n",
            "Batch: 913 of 1055\n",
            "Batch: 914 of 1055\n",
            "Batch: 915 of 1055\n",
            "Batch: 916 of 1055\n",
            "Batch: 917 of 1055\n",
            "Batch: 918 of 1055\n",
            "Batch: 919 of 1055\n",
            "Batch: 920 of 1055\n",
            "Batch: 921 of 1055\n",
            "Batch: 922 of 1055\n",
            "Batch: 923 of 1055\n",
            "Batch: 924 of 1055\n",
            "Batch: 925 of 1055\n",
            "Batch: 926 of 1055\n",
            "Batch: 927 of 1055\n",
            "Batch: 928 of 1055\n",
            "Batch: 929 of 1055\n",
            "Batch: 930 of 1055\n",
            "Batch: 931 of 1055\n",
            "Batch: 932 of 1055\n",
            "Batch: 933 of 1055\n",
            "Batch: 934 of 1055\n",
            "Batch: 935 of 1055\n",
            "Batch: 936 of 1055\n",
            "Batch: 937 of 1055\n",
            "Batch: 938 of 1055\n",
            "Batch: 939 of 1055\n",
            "Batch: 940 of 1055\n",
            "Batch: 941 of 1055\n",
            "Batch: 942 of 1055\n",
            "Batch: 943 of 1055\n",
            "Batch: 944 of 1055\n",
            "Batch: 945 of 1055\n",
            "Batch: 946 of 1055\n",
            "Batch: 947 of 1055\n",
            "Batch: 948 of 1055\n",
            "Batch: 949 of 1055\n",
            "Batch: 950 of 1055\n",
            "Batch: 951 of 1055\n",
            "Batch: 952 of 1055\n",
            "Batch: 953 of 1055\n",
            "Batch: 954 of 1055\n",
            "Batch: 955 of 1055\n",
            "Batch: 956 of 1055\n",
            "Batch: 957 of 1055\n",
            "Batch: 958 of 1055\n",
            "Batch: 959 of 1055\n",
            "Batch: 960 of 1055\n",
            "Batch: 961 of 1055\n",
            "Batch: 962 of 1055\n",
            "Batch: 963 of 1055\n",
            "Batch: 964 of 1055\n",
            "Batch: 965 of 1055\n",
            "Batch: 966 of 1055\n",
            "Batch: 967 of 1055\n",
            "Batch: 968 of 1055\n",
            "Batch: 969 of 1055\n",
            "Batch: 970 of 1055\n",
            "Batch: 971 of 1055\n",
            "Batch: 972 of 1055\n",
            "Batch: 973 of 1055\n",
            "Batch: 974 of 1055\n",
            "Batch: 975 of 1055\n",
            "Batch: 976 of 1055\n",
            "Batch: 977 of 1055\n",
            "Batch: 978 of 1055\n",
            "Batch: 979 of 1055\n",
            "Batch: 980 of 1055\n",
            "Batch: 981 of 1055\n",
            "Batch: 982 of 1055\n",
            "Batch: 983 of 1055\n",
            "Batch: 984 of 1055\n",
            "Batch: 985 of 1055\n",
            "Batch: 986 of 1055\n",
            "Batch: 987 of 1055\n",
            "Batch: 988 of 1055\n",
            "Batch: 989 of 1055\n",
            "Batch: 990 of 1055\n",
            "Batch: 991 of 1055\n",
            "Batch: 992 of 1055\n",
            "Batch: 993 of 1055\n",
            "Batch: 994 of 1055\n",
            "Batch: 995 of 1055\n",
            "Batch: 996 of 1055\n",
            "Batch: 997 of 1055\n",
            "Batch: 998 of 1055\n",
            "Batch: 999 of 1055\n",
            "Batch: 1000 of 1055\n",
            "Batch: 1001 of 1055\n",
            "Batch: 1002 of 1055\n",
            "Batch: 1003 of 1055\n",
            "Batch: 1004 of 1055\n",
            "Batch: 1005 of 1055\n",
            "Batch: 1006 of 1055\n",
            "Batch: 1007 of 1055\n",
            "Batch: 1008 of 1055\n",
            "Batch: 1009 of 1055\n",
            "Batch: 1010 of 1055\n",
            "Batch: 1011 of 1055\n",
            "Batch: 1012 of 1055\n",
            "Batch: 1013 of 1055\n",
            "Batch: 1014 of 1055\n",
            "Batch: 1015 of 1055\n",
            "Batch: 1016 of 1055\n",
            "Batch: 1017 of 1055\n",
            "Batch: 1018 of 1055\n",
            "Batch: 1019 of 1055\n",
            "Batch: 1020 of 1055\n",
            "Batch: 1021 of 1055\n",
            "Batch: 1022 of 1055\n",
            "Batch: 1023 of 1055\n",
            "Batch: 1024 of 1055\n",
            "Batch: 1025 of 1055\n",
            "Batch: 1026 of 1055\n",
            "Batch: 1027 of 1055\n",
            "Batch: 1028 of 1055\n",
            "Batch: 1029 of 1055\n",
            "Batch: 1030 of 1055\n",
            "Batch: 1031 of 1055\n",
            "Batch: 1032 of 1055\n",
            "Batch: 1033 of 1055\n",
            "Batch: 1034 of 1055\n",
            "Batch: 1035 of 1055\n",
            "Batch: 1036 of 1055\n",
            "Batch: 1037 of 1055\n",
            "Batch: 1038 of 1055\n",
            "Batch: 1039 of 1055\n",
            "Batch: 1040 of 1055\n",
            "Batch: 1041 of 1055\n",
            "Batch: 1042 of 1055\n",
            "Batch: 1043 of 1055\n",
            "Batch: 1044 of 1055\n",
            "Batch: 1045 of 1055\n",
            "Batch: 1046 of 1055\n",
            "Batch: 1047 of 1055\n",
            "Batch: 1048 of 1055\n",
            "Batch: 1049 of 1055\n",
            "Batch: 1050 of 1055\n",
            "Batch: 1051 of 1055\n",
            "Batch: 1052 of 1055\n",
            "Batch: 1053 of 1055\n",
            "Batch: 1054 of 1055\n",
            "Batch: 1055 of 1055\n",
            "Average BLEU score: 0.01867569706677278\n",
            "Batch: 1 of 186\n",
            "Batch: 2 of 186\n",
            "Batch: 3 of 186\n",
            "Batch: 4 of 186\n",
            "Batch: 5 of 186\n",
            "Batch: 6 of 186\n",
            "Batch: 7 of 186\n",
            "Batch: 8 of 186\n",
            "Batch: 9 of 186\n",
            "Batch: 10 of 186\n",
            "Batch: 11 of 186\n",
            "Batch: 12 of 186\n",
            "Batch: 13 of 186\n",
            "Batch: 14 of 186\n",
            "Batch: 15 of 186\n",
            "Batch: 16 of 186\n",
            "Batch: 17 of 186\n",
            "Batch: 18 of 186\n",
            "Batch: 19 of 186\n",
            "Batch: 20 of 186\n",
            "Batch: 21 of 186\n",
            "Batch: 22 of 186\n",
            "Batch: 23 of 186\n",
            "Batch: 24 of 186\n",
            "Batch: 25 of 186\n",
            "Batch: 26 of 186\n",
            "Batch: 27 of 186\n",
            "Batch: 28 of 186\n",
            "Batch: 29 of 186\n",
            "Batch: 30 of 186\n",
            "Batch: 31 of 186\n",
            "Batch: 32 of 186\n",
            "Batch: 33 of 186\n",
            "Batch: 34 of 186\n",
            "Batch: 35 of 186\n",
            "Batch: 36 of 186\n",
            "Batch: 37 of 186\n",
            "Batch: 38 of 186\n",
            "Batch: 39 of 186\n",
            "Batch: 40 of 186\n",
            "Batch: 41 of 186\n",
            "Batch: 42 of 186\n",
            "Batch: 43 of 186\n",
            "Batch: 44 of 186\n",
            "Batch: 45 of 186\n",
            "Batch: 46 of 186\n",
            "Batch: 47 of 186\n",
            "Batch: 48 of 186\n",
            "Batch: 49 of 186\n",
            "Batch: 50 of 186\n",
            "Batch: 51 of 186\n",
            "Batch: 52 of 186\n",
            "Batch: 53 of 186\n",
            "Batch: 54 of 186\n",
            "Batch: 55 of 186\n",
            "Batch: 56 of 186\n",
            "Batch: 57 of 186\n",
            "Batch: 58 of 186\n",
            "Batch: 59 of 186\n",
            "Batch: 60 of 186\n",
            "Batch: 61 of 186\n",
            "Batch: 62 of 186\n",
            "Batch: 63 of 186\n",
            "Batch: 64 of 186\n",
            "Batch: 65 of 186\n",
            "Batch: 66 of 186\n",
            "Batch: 67 of 186\n",
            "Batch: 68 of 186\n",
            "Batch: 69 of 186\n",
            "Batch: 70 of 186\n",
            "Batch: 71 of 186\n",
            "Batch: 72 of 186\n",
            "Batch: 73 of 186\n",
            "Batch: 74 of 186\n",
            "Batch: 75 of 186\n",
            "Batch: 76 of 186\n",
            "Batch: 77 of 186\n",
            "Batch: 78 of 186\n",
            "Batch: 79 of 186\n",
            "Batch: 80 of 186\n",
            "Batch: 81 of 186\n",
            "Batch: 82 of 186\n",
            "Batch: 83 of 186\n",
            "Batch: 84 of 186\n",
            "Batch: 85 of 186\n",
            "Batch: 86 of 186\n",
            "Batch: 87 of 186\n",
            "Batch: 88 of 186\n",
            "Batch: 89 of 186\n",
            "Batch: 90 of 186\n",
            "Batch: 91 of 186\n",
            "Batch: 92 of 186\n",
            "Batch: 93 of 186\n",
            "Batch: 94 of 186\n",
            "Batch: 95 of 186\n",
            "Batch: 96 of 186\n",
            "Batch: 97 of 186\n",
            "Batch: 98 of 186\n",
            "Batch: 99 of 186\n",
            "Batch: 100 of 186\n",
            "Batch: 101 of 186\n",
            "Batch: 102 of 186\n",
            "Batch: 103 of 186\n",
            "Batch: 104 of 186\n",
            "Batch: 105 of 186\n",
            "Batch: 106 of 186\n",
            "Batch: 107 of 186\n",
            "Batch: 108 of 186\n",
            "Batch: 109 of 186\n",
            "Batch: 110 of 186\n",
            "Batch: 111 of 186\n",
            "Batch: 112 of 186\n",
            "Batch: 113 of 186\n",
            "Batch: 114 of 186\n",
            "Batch: 115 of 186\n",
            "Batch: 116 of 186\n",
            "Batch: 117 of 186\n",
            "Batch: 118 of 186\n",
            "Batch: 119 of 186\n",
            "Batch: 120 of 186\n",
            "Batch: 121 of 186\n",
            "Batch: 122 of 186\n",
            "Batch: 123 of 186\n",
            "Batch: 124 of 186\n",
            "Batch: 125 of 186\n",
            "Batch: 126 of 186\n",
            "Batch: 127 of 186\n",
            "Batch: 128 of 186\n",
            "Batch: 129 of 186\n",
            "Batch: 130 of 186\n",
            "Batch: 131 of 186\n",
            "Batch: 132 of 186\n",
            "Batch: 133 of 186\n",
            "Batch: 134 of 186\n",
            "Batch: 135 of 186\n",
            "Batch: 136 of 186\n",
            "Batch: 137 of 186\n",
            "Batch: 138 of 186\n",
            "Batch: 139 of 186\n",
            "Batch: 140 of 186\n",
            "Batch: 141 of 186\n",
            "Batch: 142 of 186\n",
            "Batch: 143 of 186\n",
            "Batch: 144 of 186\n",
            "Batch: 145 of 186\n",
            "Batch: 146 of 186\n",
            "Batch: 147 of 186\n",
            "Batch: 148 of 186\n",
            "Batch: 149 of 186\n",
            "Batch: 150 of 186\n",
            "Batch: 151 of 186\n",
            "Batch: 152 of 186\n",
            "Batch: 153 of 186\n",
            "Batch: 154 of 186\n",
            "Batch: 155 of 186\n",
            "Batch: 156 of 186\n",
            "Batch: 157 of 186\n",
            "Batch: 158 of 186\n",
            "Batch: 159 of 186\n",
            "Batch: 160 of 186\n",
            "Batch: 161 of 186\n",
            "Batch: 162 of 186\n",
            "Batch: 163 of 186\n",
            "Batch: 164 of 186\n",
            "Batch: 165 of 186\n",
            "Batch: 166 of 186\n",
            "Batch: 167 of 186\n",
            "Batch: 168 of 186\n",
            "Batch: 169 of 186\n",
            "Batch: 170 of 186\n",
            "Batch: 171 of 186\n",
            "Batch: 172 of 186\n",
            "Batch: 173 of 186\n",
            "Batch: 174 of 186\n",
            "Batch: 175 of 186\n",
            "Batch: 176 of 186\n",
            "Batch: 177 of 186\n",
            "Batch: 178 of 186\n",
            "Batch: 179 of 186\n",
            "Batch: 180 of 186\n",
            "Batch: 181 of 186\n",
            "Batch: 182 of 186\n",
            "Batch: 183 of 186\n",
            "Batch: 184 of 186\n",
            "Batch: 185 of 186\n",
            "Batch: 186 of 186\n",
            "Average BLEU score: 0.018788355837983477\n",
            "Train BLEU: 0.01867569706677278\n",
            "Test BLEU: 0.018788355837983477\n"
          ]
        }
      ],
      "source": [
        "train_dataset = FlickrDataset(captions=training_data, embedding=embedding)\n",
        "test_dataset = FlickrDataset(captions=test_data, embedding=embedding)\n",
        "\n",
        "# create dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
        "\n",
        "# calculate bleu scores\n",
        "train_evaluator = Evaluator(model, train_loader, device)\n",
        "test_evaluator = Evaluator(model, test_loader, device)\n",
        "\n",
        "train_bleu, train_scores = train_evaluator.evaluate()\n",
        "test_bleu, test_scores = test_evaluator.evaluate()\n",
        "\n",
        "print(f\"Train BLEU: {train_bleu}\")\n",
        "print(f\"Test BLEU: {test_bleu}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7ggCETV9GDS"
      },
      "outputs": [],
      "source": [
        "# export bleu scores\n",
        "with open(\"drive/My Drive/train_scores_without_eos.pkl\", \"wb\") as f:\n",
        "    pickle.dump(train_scores, f)\n",
        "\n",
        "with open(\"drive/My Drive/test_scores_without_eos.pkl\", \"wb\") as f:\n",
        "    pickle.dump(test_scores, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.9.15 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "8c062c6b57d91616a29c64ccda85a992f94b9c302ff6b9e6bdfcfbfa090602a1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
